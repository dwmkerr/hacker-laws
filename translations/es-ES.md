# ðŸ’»ðŸ“– hacker-laws

Leyes, TeorÃ­as, Principios y Patrones que los desarrolladores encontrarÃ¡n Ãºtiles.

[traducciones](#translations):  [ðŸ‡§ðŸ‡·](./translations/pt-BR.md) [ðŸ‡¨ðŸ‡³](https://github.com/nusr/hacker-laws-zh) [ðŸ‡«ðŸ‡·](./translations/fr.md) [ðŸ‡®ðŸ‡¹](./translations/it-IT.md) [ðŸ‡±ðŸ‡»](./translations/lv.md) [ðŸ‡°ðŸ‡·](https://github.com/codeanddonuts/hacker-laws-kr) [ðŸ‡·ðŸ‡º](https://github.com/solarrust/hacker-laws) [ðŸ‡¹ðŸ‡·](./translations/tr.md) [ðŸ‡®ðŸ‡©](./translations/id.md) [ðŸ‡¯ðŸ‡µ](./translations/jp.md) [ðŸ‡µðŸ‡±](./translations/pl.md) [ðŸ‡»ðŸ‡³](./translations/vi.md)

Â¿Te gusta este proyecto? Por favor, considera [Esponsorizarme](https://github.com/sponsors/dwmkerr)!

---

<!-- vim-markdown-toc GFM -->

* [IntroducciÃ³n](#introduccion)
* [Leyes](#leyes)
    * [Ley de Amdahl](#ley-de-amdahl)
    * [Ley de Brooks](#ley-de-brooks)
    * [Ley de Conway](#ley-de-conways)
    * [Ley de Cunningham](#ley-de-cunningham)
    * [NÃºmero de Dunbar](#numero-de-dunbar)
    * [Ley de Gall](#ley-de-gall)
    * [Cuchilla de Hanlon](#cuchilla-de-hanlon)
    * [Ley de Hofstadter](#ley-de-hofstadter)
    * [Ley de Hutber](#ley-de-hutber)
    * [El Ciclo de SobreexpectaciÃ³n y la Ley de Amara](#el-ciclo-de-sobreexpectacion-y-la-ley-de-amara)
    * [Ley de Hyrum (La Ley de las Interfaces ImplÃ­citas)](#ley-de-hyrum-la-ley-de-las-interfaces-implicitas)
    * [Ley de Metcalfe](#ley-de-metcalfe)
    * [Ley de Moore](#ley-de-moore)
    * [Ley de Murphy / Ley de Sod](#ley-de-murphy--ley-de-sod)
    * [Ley de Parkinson](#ley-de-parkinson)
    * [Efecto de OptimizaciÃ³n Prematura](#efecto-de-optimizacion-prematura)
    * [Ley de Putt](#ley-de-putt)
    * [Ley de Reed](#ley-de-reed)
    * [Ley de ConservaciÃ³n de Complejidad (Ley de Tesler)](#ley-de-conservacion-de-complejidad-ley-de-tesler)
    * [Ley de Abstracciones Permeables](#ley-de-abstracciones-permeables)
    * [Ley de la Trivialidad](#ley-de-la-trivialidad)
    * [FilosofÃ­a Unix](#filosofia-unix)
    * [El Modelo Spotify](#el-modelo-spotify)
    * [Ley de Wadler](#ley-de-wadler)
* [Principios](#principios)
    * [El Principio de Dilbert](#el-principio-de-dilbert)
    * [El Principio de Pareto (La Regla 80/20)](#el-principio-de-pareto-la-regla-8020)
    * [El Principio de Peter](#el-principio-de-peter)
    * [El Principio de la Robustez (Ley de Postel)](#el-principio-de-la-robustez-ley-de-postel)
    * [SOLID](#solid)
    * [El Principio de Ãšnica Responsabilidad](#el-principio-de-unica-responsabilidad)
    * [El Principio Abierto/Cerrado](#el-principio-abierto-cerrado)
    * [El Principio de SustituciÃ³n de Liskov](#el-principio-de-sustitucion-de-liskov)
    * [El Principio de SegregaciÃ³n de Interfaz](#el-principio-de-segregacion-de-interfaz)
    * [El Principio de InversiÃ³n de Dependencia](#el-principio-de-inversion-de-dependencia)
    * [El Principio DRY](#el-principio-dry)
    * [El Principio KISS](#el-principio-kiss)
    * [YAGNI](#yagni)
* [Lista de Lectura](#lista-de-lectura)
* [POR-HACER](#por-hacer)

<!-- vim-markdown-toc -->

## IntroducciÃ³n

Hay montones de leyes que la gente discute cuando habla sobre desarrollo. Este repositorio es una referencia y un resumen de algunos de los mÃ¡s conocidos. Por favor, Â¡comparte y sube tus PRs!

â—: Este repositorio contiene una explicaciÃ³n sobre algunas leyes, principios y patrones, pero no _defendemos_ ninguno de ellos. Si estos pueden ser aplicados o no siempre serÃ¡ materia de debate y muy dependiente de en quÃ© estÃ©s trabajando.

## Leyes

Â¡Y aquÃ­ vamos!

### Ley de Amdahl

[Ley de Amdahl en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Amdahl)

> La ley de Amdahl se puede interpretar de manera mÃ¡s tÃ©cnica, pero en tÃ©rminos simples, significa que es el algoritmo el que decide la mejora de velocidad, no el nÃºmero de procesadores. Finalmente se llega a un momento que no se puede paralelizar mÃ¡s el algoritmo.

Mejor lo ilustramos con un ejemplo. Si un programa se compone de dos partes, la parte A debe ser ejecutada en un solo procesador y la parte B puede ser paralelizada, entonces vemos que agregamos mÃºltiples procesadores al sistema en ejecuciÃ³n ese programa puede solo tener un beneficio limitado. Este puede potencialmente mejorar mucho la velocidad de la parte B - pero la velocidad de la parte A se mantendrÃ¡ sin cambios.

El diagrama de abajo muestra algunos ejemplos de mejoras potenciales en velocidad:

![Diagram: Amdahl's Law](./images/amdahls_law.png)

*(Imagen de Referencia: Por Daniels220 en Wikipedia, Creative Commons Attribution-Share Alike 3.0 Unported, https://en.wikipedia.org/wiki/File:AmdahlsLaw.svg)*

Como podemos ver, incluso un programa el cual es un 50% paralelizable se beneficiarÃ¡ muy poco mÃ¡s allÃ¡ de 10 unidades de procesamiento, mientras que un programa el cual es 95% paralelizable todavÃ­a puede alcanzar mejoras significativas de velocidad con mÃ¡s de mil unidades de procesamiento.

A medida que la [Ley de Moore](#ley-de-moore) se ralentiza y la aceleraciÃ³n de la velocidad del procesador individual disminuye, la paralelizaciÃ³n es la clave para incrementar el rendimiento.La programaciÃ³n de grÃ¡ficos es un excelente ejemplo: con la informÃ¡tica moderna basada en Shader, pÃ­xeles individuales o fragmentos pueden ser renderizados en paralelo. Este es el porquÃ© las tarjetas grÃ¡ficas modernas en ocasiones disponen de miles de nÃºcleos de procesamiento (GPUs o Unidades de Shader).

Vea tambiÃ©n:

- [Ley de Brooks](#ley-de-brooks)
- [Ley de Moore](#ley-de-moore)

### Ley de Brooks

[Ley de Brooks en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Brooks)

> Cuando se incorpora una persona en un proyecto, Ã©ste se ralentiza en lugar de acelerarse. Brooks tambiÃ©n afirmÃ³ que "Nueve mujeres no pueden tener un bebÃ© en un mes".

Esta ley sugiere que en muchos casos, intentar acelerar la entrega de un proyecto el cual ya va tarde, agregando mÃ¡s personas, harÃ¡ que la entrega vaya aÃºn mÃ¡s tarde. Brooks clarifica que esto es una simplificaciÃ³n, sin embargo, el razonamiento general es que el tiempo de aceleraciÃ³n de nuevos recursos y la sobrecarga de comunicaciÃ³n, en el inmediato corto plazo hace que la velocidad caiga. TambiÃ©n, muchas tareas pueden no ser divisibles, es decir que pueden no ser fÃ¡cilmente distribuibles entre mÃ¡s personas, significando que el potencial incremento de velocidad es incluso menor.

La frase comÃºn en entregas "Nueve mujeres no pueden tener un bebÃ© en un mes" estÃ¡ relacionada a la Ley de Brooks, en particular, al hecho de que algunos tipos de trabajos no son divisibles ni paralelizables.

Este es el tema central del libro '[El MÃ­tico Hombre Mes](#lista-de-lectura)'.

Vea tambiÃ©n:

- [Marcha de la Muerte](#todo)
- [Lista de Lectura: El MÃ­tico Hombre Mes](#reading-list)

### Ley de Conway

[La Ley de Conway en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Conway)

Esta ley sugiere que los lÃ­mites tÃ©cnicos de un sistema reflejan la estructura de la organizaciÃ³n. Es comÃºnmente referido a cuando se observan mejoras de una organizaciÃ³n, la Ley de Conway sugiere que si una organizaciÃ³n es estructurada en muchas unidades pequeÃ±as y desconectadas, el software que producirÃ¡ serÃ¡ asÃ­. Si una organizaciÃ³n es construÃ­da mÃ¡s entorno a soluciones 'verticales' las cuales estÃ¡n orientadas alrededor de caracterÃ­sticas o servicios, los sistemas de software tambiÃ©n reflejarÃ¡n esto.

Vea tambiÃ©n:

- [El Modelo Spotify](#el-modelo-spotify)

### Ley de Cunningham

[Ley de Cunningham en Wikipedia](https://meta.wikimedia.org/wiki/Cunningham%27s_Law/es)

> La mejor forma de obtener la respuesta correcta en Internet no es hacer una pregunta, es enviar la respuesta errÃ³nea.

Acorde a Steven McGeady, Ward Cunningham le aconsejÃ³ a principios de los 80: "La mejor forma de obtener la respuesta correcta en Internet no es hacer una pregunta, es enviar una respuesta incorrecta." McGeady lo llamÃ³ la Ley de Cunningham, sin embargo Cunningham niega su propiedad diciendo que es una cita errÃ³nea. Aunque originalmente se refiere a las interacciones en Usenet, la ley ha sido usada para describir como otras comunidades online funcionan (e.g., Wikipedia, Reddit, Twitter, Facebook).

Vea tambiÃ©n:

- [XKCD 386: "Duty Calls" (El Deber Llama)](https://xkcd.com/386/)

### El NÃºmero de Dunbar

[El NÃºmero de Dunbar en Wikipedia](https://es.wikipedia.org/wiki/N%C3%BAmero_de_Dunbar)

"El nÃºmero de Dunbar es un lÃ­mite cognitivo sugerido sobre el nÃºmero de personas con las que puedes mantener relaciones sociables estables- relaciones en las que un individuo sabe quien es la otra persona and cÃ³mo cada persona se relaciona con cada una de las otras personas." Hay algÃºn desacuerdo sobre el nÃºmero exacto. "... [Dunbar] propuso que los humanos pueden mantener cÃ³modamente solo 150 relaciones estables." El puso el nÃºmero dentro de un contexto mÃ¡s social, "el nÃºmero de personas con las que no sentirÃ­as vergÃ¼enza de invitarlas a tomar una copa
"Dunbar's number is a suggested cognitive limit to the number of people with whom one can maintain stable social relationshipsâ€” relationships in which an individual knows who each person is and how each person relates to every other person." There is some disagreement to the exact number. "... [Dunbar] proposed that humans can comfortably maintain only 150 stable relationships." He put the number into a more social context, "la cantidad de personas de las que no te sentirÃ­as avergonzado por unirte sin invitaciÃ³n a tomar una copa si te topas con ellas en un bar." Estima que el nÃºmero puede rondar generalmente entre 100 y 250.

Al igual que relaciones estables entre individuos, la relaciÃ³n de un desarrollador con su cÃ³digo base toma esfuerzo mantenerla. Cuando afrontas un gran nÃºmero de proyectos complicados o creas muchos proyectos, nos apoyamos en convenciones, polÃ­ticas y modelamos procedimientos para escalar. El nÃºmero de Dunbar no es solo importante para tener en mente como una oficina crece, tambiÃ©n cuando configuramos el alcance de los esfuerzos de un equipo o decidimos cuando debemos invertir en herramientas para asistir en el modelado y automatizar el sobregasto logÃ­stico. Poniendo el nÃºmero en el contexto de ingenierÃ­a, es el nÃºmero de proyectos (o complejidad normalizada de un Ãºnico proyecto) para los cuales podrÃ­as sentirte seguro de unirte para las rondas de soporte telefÃ³nico.

Vea tambiÃ©n:

- [Ley de Conway](#ley-de-conway)

### Ley de Gall

[Ley de Gall en Wikipedia (inglÃ©s)](https://en.wikipedia.org/wiki/John_Gall_(author)#Gall's_law)

> Un sistema complejo que funciona ha sido evolucionado invariablemente desde un sistema simple que funcionaba. Un sistema complejo diseÃ±ado desde cero nunca funcionarÃ¡ y no puede ser arreglado para que funcione. Tienes que comenzar de nuevo con un sistema simple que funcione.
>
> ([John Gall](https://en.wikipedia.org/wiki/John_Gall_(author)))


La Ley de Gall implica que los intentos de _diseÃ±ar_ un sistema altamente complejo tenderÃ¡n siempre a fallar. Sistemas altamente complejos son raramente construidos de una sola vez, estos suelen ser evoluciones de sistemas mucho mÃ¡s simples.

El ejemplo clÃ¡sico es la World Wide Web (WWW). En su estado actual, es un sistema altamente complejo. Sin embargo, esta fue definida inicialmente como una forma simple de compartir contenido entre instituciones acadÃ©micas. Esta fue un Ã©xito cumpliendo sus objetivos y evolucionÃ³ para llegar a ser mÃ¡s compleja con el tiempo.

Vea tambiÃ©n:

- [KISS (Keep It Simple, Stupid)](#el-principio-kiss)

### La Navaja de Hanlon

[La Navaja de Hanlon en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_Hanlon)

> Nunca atribuyas a la malicia lo que puede ser adecuadamente explicado por la estupidez.
>
> Robert J. Hanlon

Este principio sugiere que las acciones resultantes en un resultado negativo no fueron resultado de una mala intenciÃ³n. En su lugar el resultado negativo es mejor atribuÃ­do a que esas acciones y/o el impacto no fueron completamente entendidos.

### Ley de Hofstadter

[Ley de Hofstadter en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Hofstadter)

> Siempre lleva mÃ¡s tiempo de lo que esperas, incluso si tienes en cuenta la Ley de Hofstadter.
>
> (Douglas Hofstadter)

QuizÃ¡s hayas oÃ­do esta ley referida a cuando se busca estimar el tiempo que tomarÃ¡ algo. Esto parece una verdad absoluta en el desarrollo de software donde tendemos a no ser muy buenos estimando con precisiÃ³n cuanto tiempo tomarÃ¡ entregar algo.

Esto proviene del libro '[GÃ¶del, Escher, Bach: An Eternal Golden Braid](#lista-de-lectura)'.

Vea tambiÃ©n:

- [Lista de lectura: GÃ¶del, Escher, Bach: An Eternal Golden Braid](#lista-de-lectura)

### Ley de Hutber

[Ley de Hutber en Wikipedia (inglÃ©s)](https://en.wikipedia.org/wiki/Hutber%27s_law)

> Mejorar signfica deteriorar.
>
> ([Patrick Hutber (inglÃ©s)](https://en.wikipedia.org/wiki/Patrick_Hutber))

Esta ley sugiere que las mejoras realizadas en un sistema llevarÃ¡n a su deterioro en otras partes, u ocultarÃ¡ otros deterioros, llevando a una degradaciÃ³n total del estado actual del sistema.

Por ejemplo, un decremento en la latencia de respuesta para un end-point particular podrÃ­a causar problemas de rendimiento y capacidad de procesamiento mÃ¡s adelante en el flujo de peticiones, afectando a un subsistema completamente diferente.

### El Ciclo de SobreexpectaciÃ³n y La Ley de Amara

[El Ciclo de SobreexpectaciÃ³n](https://es.wikipedia.org/wiki/Ciclo_de_sobreexpectaci%C3%B3n)

> Tendemos a sobreestimar el efecto de una tecnologÃ­a a corto plazo y subestimar su efecto a largo plazo.
>
> (Roy Amara)

El Ciclo de SobreexpectaciÃ³n es una representaciÃ³n visual de la excitaciÃ³n y desarrollo de tecnologÃ­a a lo largo del tiempo, originalmente producido por Gartner. Se explica mejor de forma visual:

![El Cico de SobreexpectaciÃ³n](./images/gartner_hype_cycle.png)

*(Referencia de Imagen: Por Jeremykemp en Wikipedia, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=10547051)*

En pocas palabras, el ciclo sugiere que hay una tÃ­pica burbuja de excitaciÃ³n alrededor de cada nueva tecnologÃ­a y su impacto potencial. Los equipos a veces saltan rÃ¡pidamente a emplear estas tecnologÃ­as y a veces se encuentran a sÃ­ mismos decepcionados con los resultados. Esto puede ser porque la tecnologÃ­a no es aÃºn lo suficientemente madura, o las aplicaciones del mundo real no estÃ¡n completamente desarrolladas. DespuÃ©s de cierto tiempo, las capacidades de la tecnologÃ­a se incrementan y las oportunidades de ser empleada de forma prÃ¡ctica aumentan permitiendo a los equipos ser finalmente productivos. La frase de Roy Amara resume este hecho de forma breve - "Tendemos a sobreestimar el efecto de una tecnologÃ­a a corto plazo y subestimarla a largo plazo".

### Ley de Hyrum (La Ley de las Interfaces ImplÃ­citas)

[Ley de Hyrum (inglÃ©s)](http://www.hyrumslaw.com/)

> Con un nÃºmero suficiente de usuarios de una API,
> no importa que prometas en el contrato:
> alguien dependerÃ¡ de todos los comportamientos observables
> de tu sistema.
>
> (Hyrum Wright)

La Ley de Hyrum establece que cuando tienes un _nÃºmero grande y suficiente de consumidores_ de una API, todos los comportamientos de la API (incluso aquellos no definidos como parte del contrato pÃºblico) llegarÃ¡n de forma eventual a ser dependencia de alguien. Un ejemplo trivial pueden ser los elementos no-funcionales como el tiempo de respuesta de una API. Un ejemplo mÃ¡s sutil puede ser quÃ© consumidores estÃ¡n dependiendo en la aplicaciÃ³n de una expresiÃ³n regular sobre un mensaje de error para determinar el *tipo* de error de una API. Incluso si el contrato pÃºblico de la API no establece nada acerca del contenido del mensaje de error indicando a los usuarios que deben emplear un cÃ³digo de error, _algunos_ usuarios usarÃ¡n el mensaje y cambiar el mensaje esencialmente romperÃ¡ la API para estos usuarios.

Vea tambiÃ©n:

- [La Ley de las Abstracciones Permeables](#la-ley-de-las-abstracciones-permeables)
- [XKCD 1172](https://xkcd.com/1172/)


### Ley de Metcalfe

[Ley de Metcalfe en Wikipedia (inglÃ©s)](https://en.wikipedia.org/wiki/Metcalfe's_law)

> En teorÃ­a de redes, el nÃºmero en el que un sistema crece es aproximadamente el cuadrado del nÃºmero de usuarios de ese sistema.

Esta ley estÃ¡ basada en el nÃºmero de posibles conexiones por pares dentro de un sistema y estÃ¡ muy relacionado con [La Ley de Reed](#ley-de-reed). Odlyzko y otros han argumentado que ambas leyes (Reed y Metcalfe) exageran el valor de un sistema por no tener en cuenta los lÃ­mites de la cogniciÃ³n humana en efectos de redes; vea [El NÃºmero de Dunbar](#numero-de-dunbar).

Vea tambiÃ©n:
- [Ley de Reed](#ley-de-reed)
- [NÃºmero de Dunbar](#numero-de-dunbar)

### Ley de Moore

[Ley de Moore en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Moore)

> El nÃºmero de transistores en un circuito integrado se dobla aproximadamente cada dos aÃ±os.

A veces empleado para ilustrar la velocidad pura a la que un semiconductor y la tecnologÃ­a de chips ha mejorado, la predicciÃ³n de Moore probÃ³ ser altamente precisa desde los 70 hasta finales de la primera dÃ©cada de 2000. En los aÃ±os recientes, la tendencia ha cambiado ligeramente, parcialmente debido a [las limitaciones fÃ­sicas en el grado en el que los componentes pueden ser miniaturizados (inglÃ©s)](https://en.wikipedia.org/wiki/Quantum_tunnelling). Sin embargo, los avances en la paralelizaciÃ³n y potencialmente los cambios revolucionarios en la tecnologÃ­a de semiconductores y computaciÃ³n cuÃ¡ntica puedan significar que la Ley de Moore continÃºe siendo cierta en las siguientes dÃ©cadas.

### Ley de Murphy / Ley de Sod

[Ley de Murphy en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Murphy)

> Si algo puede ir mal, irÃ¡ mal.

Relacionado con [Edward A. Murphy, Jr](https://es.wikipedia.org/wiki/Edward_A._Murphy_Jr.) la _Ley de Murphy_ establece que si algo puede ir mal, irÃ¡ mal.

Este dicho es muy comÃºn entre desarrolladores. A veces algo inesperado sucede cuando se desarrolla, se hacen pruebas o incluso en producciÃ³n. Esto puede relacionarse tambiÃ©n a la (mÃ¡s comÃºn en inglÃ©s britÃ¡nico) _Ley de Sod_:

> Si algo puede ir mal, irÃ¡ mal, en el peor momento posible.

Estas leyes son generalmente empleadas en sentido cÃ³mico. Sin embargo, tales fenÃ³menos como la [_Sesgo de ConfirmaciÃ³n_](#por-hacer) y [_Sesgo de SelecciÃ³n_](#por-hacer) pueden llevar a la gente a sobre-enfatizar estas leyes (la mayorÃ­a de las veces cuando las cosas funcionan, estas pasan sin tenerse en cuenta, mientras que los fallos son muy notalbes y entran mÃ¡s en las conversaciones).

Vea tambiÃ©n:

- [Sesgo de ConfirmaciÃ³n](#por-hacer)
- [Sesgo de SelecciÃ³n](#por-hacer)

### Ley de Parkinson

[Ley de Parkinson en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Parkinson)

> El trabajo se expande hasta llenar el tiempo disponible para que se termine.

En su contexto original, esta Ley se basÃ³ en estudios de burocracias. Esta podÃ­a ser aplicada de forma pesimista a las iniciativas de desarrollo de software, la teorÃ­a serÃ­a que los equipos serÃ¡n ineficientes hasta que la fecha de entrega estÃ© cerca, entonces se apresurarÃ¡n a completar el trabajo para la entrega, haciendo la fecha de entrega real de algÃºn modo arbitraria.

Si esta ley se combina con la [Ley de Hofstadter](#ley-de-hofstadter), un punto de vista incluso mÃ¡s pesimista es alcanzado - el trabajo se expandirÃ¡ hasta rellenar el tiempo disponible para su compleciÃ³n y *aÃºn tomarÃ¡ mÃ¡s tiempo del esperado*.

Vea tambiÃ©n:

- [Ley de Hofstadter](#ley-de-hofstadter)

### Efecto de OptimizaciÃ³n Prematura

[OptimizaciÃ³n Prematura en Wikipedia](https://es.wikipedia.org/wiki/Optimizaci%C3%B3n_de_software#Cu%C3%A1ndo_optimizar)

> Debemos olvidar las pequeÃ±as eficiencias, por ejemplo, el 97% del tiempo: la optimizaciÃ³n prematura es la raÃ­z de todos los males.
>
> [(Donald Knuth, diciembre de 1974)](https://twitter.com/realdonaldknuth)

En el documento de Donald Knuth titulado [ProgramaciÃ³n Estructurada con Mandatos Go To (inglÃ©s)](http://wiki.c2.com/?StructuredProgrammingWithGoToStatements), escribiÃ³: "Los programadores desperdician enormes cantidades de tiempo pensando o preocupÃ¡ndose acerca de la velocidad de partes no-crÃ­ticas de sus programas, y esos intentos de eficiencia en realidad tienen un impacto negativo cuando consideramos la depuraciÃ³n o el mantenimiento. Debemos olvidar las pequeÃ±as eficiencias, por ejemplo, el 97% del tiempo: **la optimizaciÃ³n prematura es la raÃ­z de todos los males**. Aunque no debemos dejar pasar nuestras oportunidades en ese crÃ­tico 3%."

Sin embargo, _Premature Optimization_ puede ser definido (en tÃ©rminos menos cargados) como nosotros sabemos lo que tenemos que hacer.

### Ley de Putt

[Ley de Putt (inglÃ©s)](https://en.wikipedia.org/wiki/Putt%27s_Law_and_the_Successful_Technocrat)

> La TecnologÃ­a es dominada por dos tipos de personas, aquellos quienes comprenden lo que no controlan y aquellos quienes controllan lo que no entienden.

La Ley de Putt a veces es seguida por el Corolario de Putt:

> Cada jerarquÃ­a tÃ©cnica, con el tiempo, desarrolla una inversiÃ³n de competencia.

Estos mandatos sugieren que debido a varios criterios de selecciÃ³n y tendencias en cÃ³mo los grupos se organizan, habrÃ¡ un nÃºmero de personas cualificadas en los niveles de trabajo de una organizaciÃ³n tÃ©cnica y una cantidad de personas en roles directivos que no son conscientes de las complejidades y desafÃ­os del trabajo que estÃ¡n manejando. Esto puede ser debido al fenÃ³menos tales como [El Principio de Peter](#el-principio-de-peter) o [El Principio de Dilbert](#el-principio-de-dilbert).

Sin embargo, debe enfatizarse que leyes como esta son generalizaciones amplias y pueden aplicarse a _algunos_ tipos de organizaciones y no a otras.

Vea tambiÃ©n:

- [El Principio de Peter](#el-principio-de-peter)
- [El Principio de Dilbert](#el-principio-de-dilbert)

### La Ley de Reed

[La Ley de Reed en Wikipedia (inglÃ©s)](https://en.wikipedia.org/wiki/Reed's_law)

> La utilidad de redes grandes, particularmente redes sociales, escala exponencialmente con el tamaÃ±o de la red.

Esta ley estÃ¡ basada en la teorÃ­a de grafos, donde la utilidad escala como el nÃºmero de posibles sub-grupos, el cuÃ¡l es mÃ¡s rÃ¡pido que el nÃºmero de participantes o el nÃºmero de posibles conexiones p
Esta ley se basa en la teorÃ­a de grafos, donde la utilidad se escala como el nÃºmero de subgrupos posibles, que es mÃ¡s rÃ¡pido que el nÃºmero de participantes o el nÃºmero de posibles conexiones por pares. Odlyzko y otros han argumentado que la Ley de Reed exagera la utilidad del sistema al no tener en cuenta los lÃ­mites de la cogniciÃ³n humana sobre los efectos de la red; ver [El NÃºmero de Dunbar](#numero-de-dunbar).

See also:
- [La Ley de Metcalfe's Law](#metcalfes-law)
- [NÃºmero de Dunbar](#numero-de-dunbar)

### Ley de ConservaciÃ³n de Complejidad (Ley de Tesler)

[La Ley de ConservaciÃ³n de Complejidad en Wikipedia (inglÃ©s)](https://en.wikipedia.org/wiki/Law_of_conservation_of_complexity)

Esta ley establece que hay una cierta cantidad de complejidad en un sistema la cuÃ¡l no puede ser reducida.

Cierta complejidad en un sistema puede ser 'involuntaria'. Es consecuencia de una estructura deficiente, errores o tan solo un mal modelo de un problema a resolver. La complejidad involuntaria puede ser reducida (o eliminada). Sin embargo, cierta complejidad es 'intrÃ­nseca' como consecuencia de la complejidad inherente de un problema que se estÃ¡ resolviendo. Esta complejidad puede ser desplazada, pero no eliminada.

Un elemento interesate de esta ley es la sugerencia de que incluso simplificando el sistema entero, la complejidad intrÃ­nseca no se reduce, esta se _desplaza hacia el usuario_, el cuÃ¡l debe comportarse de una forma compleja.

### Ley de las Abstracciones Permeables

[La Ley de las Abstracciones Permeables en Joel on Software (inglÃ©s)](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/)

> Toda abstracciÃ³n no trivial, en algÃºn grado, es permeable.
>
> ([Joel Spolsky](https://twitter.com/spolsky))

Esta ley establece que las abstracciones, las cuales son generalmente usadas en computaciÃ³n para simplificar el trabajo con sistemas complicados, en ciertas situaciones 'filtrarÃ¡n' sus elementos a un sistema subyacente, haciendo que la abstracciÃ³n se comporte de una forma inesperada.

Un ejemplo puede ser la carga de un fichero y lectura de sus contenidos. Las APIs del sistema de ficheros son una _abstracciÃ³n_ del bajo nivel de los sistemas del kernel, los cuales son en sÃ­ mismos abstracciones de los procesos fÃ­sicos relacionados con el cambio de informaciÃ³n en un disco magnÃ©tico (o memoria flash para un SSD). En la mayorÃ­a de los casos, funcionarÃ¡ la abstracciÃ³n de tratar al fichero como un flujo de datos binarios. Sin embargo, para un disco magnÃ©tico, leer datos secuenciales puede ser *significativamente* mÃ¡s rÃ¡pido que los accesos aleatorios (debido al aumento de la sobrecarga de fallas), pero no para un disco SSD donde este aumento no estarÃ¡ presente. Los detalles subyacentes necesitarÃ¡n ser entendidos para tratar cada caso (por ejemplo, Ã­ndices de base de datos son estructurados para reducir la sobrecarga del acceso aleatorio), la abstracciÃ³n 'filtra' detalles de la implementaciÃ³n al desarrollador que pueda necesitar tener en cuenta.

El ejemplo anterior puede llegar a ser aÃºn mÃ¡s complejo cuando _mÃ¡s_ abstracciones sean introducidas. El sistema operativo Linux permite acceder a ficheros en red pero representados de forma local como ficheros 'normales'. Esta abstracciÃ³n 'filtrarÃ¡' si hay errores de red. Si un desarrollador trata estos ficheros como 'normales', sin considerar el hecho de que puedan estar sujetos a latencia de red y fallos, las soluciones serÃ¡n defectuosas.

El artÃ­culo que describe esta ley sugiere que una dependenica excesiva de abstracciones, combinada con un entendimiento deficiente del proceso subyacente, en realidad hace que tratar con el problema sea _mÃ¡s_ complejo en algunos casos.

Vea tambiÃ©n:

- [Ley de Hyrum](#ley-de-hyrum-la-ley-de-las-interfaces-implicitas)

Ejemplos del Mundo-Real:

- [Inicio lento en Photoshop (inglÃ©s)](https://forums.adobe.com/thread/376152) - un problema que encontrÃ© en el pasado. Photoshop podrÃ­a tener un inicio lento, algunas veces tomando incluso minutos. Parece que el problema fue debido a que al inicio lee cierta informaciÃ³n sobre la impresora por defecto. Sin embargo, si la impresora estÃ¡ en red, esto puede tomar mucho tiempo. La _abstracciÃ³n_ de una impresora en red siendo presentada al sistema de forma similar a una impresora local causÃ³ un problema para usuarios en situaciones de conectividad de red deficiente.

### Ley de la Trivialidad

[Ley de la Trivialidad en Wikipedia (inglÃ©s)](https://en.wikipedia.org/wiki/Law_of_triviality)

Esta ley sugiere que los grupos invertirÃ¡n mucho mÃ¡s tiempo y atenciÃ³n a problemas triviales y cosmÃ©ticos que a problemas serios y sustanciales.

El ejemplo comÃºn y ficticio usado para ilustrarlo es que un comitÃ© aprobando planes para una planta nuclear invertirÃ¡ la mayor parte del tiempo discutiendo la estructura del aparcamiento de bicicletas que diseÃ±os mucho mÃ¡s importantes para la planta nuclear en sÃ­ misma. Puede ser difÃ­cil hacer aportes valiosos en las discusiones sobre temas muy grandes y complejos sin un alto grado de experiencia y preparaciÃ³n en el tema. Sin embargo, la gente quiere ser vista contribuyendo de forma valiosa. De ahÃ­ la tendencia a enfocarse demasiado en detalles pequeÃ±os, los cuales pueden ser razonados fÃ¡cilmente, pero no necesariamente de particular importancia.

El ejemplo ficticio de arriba nos lleva al uso del tÃ©rmino 'Aparcamiento de Bicicletas' (Bike Shedding) como una expresiÃ³n para el desperdicio del tiempo en detalles triviales.

### FilosofÃ­a Unix

[La FilosofÃ­a Unix en Altenwald](https://altenwald.org/2008/09/22/filosofia-unix/)

La FilosofÃ­a Unix es que los componentes de software debe ser pequeÃ±os y enfocados en hacer tan solo una cosa bien. Esto puede hacer mÃ¡s fÃ¡cil construir sistemas a travÃ©s de la composiciÃ³n conjunta de pequeÃ±as, simples y bien definidas unidades mejor que usar programas grandes, complejos y multi-propÃ³sito.

PrÃ¡cticas modernas como 'Arquitectura de Microservicios' pueden ser pensadas como una aplicaciÃ³n de esta ley, donde los servicios son pequeÃ±os, enfocados y hacen una cosa especÃ­fica, permitiendo componer comportamientos mÃ¡s complejos compuestos de bloques de construcciÃ³n simples.

### El Modelo Spotify

[El Modelo Spotify en Spotify Labs (inglÃ©s)](https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/)

El Modelo Spotify es un enfoque a una estructura de organizaciÃ³n la cual ha sido popularizada por 'Spotify'. En este modelo, los equipos son organizados alrededor de caracterÃ­sticas en lugar de tecnologÃ­as.

El Modelo Spotify tambiÃ©n popularizÃ³ los conceptos de Tribus, Gremios y CapÃ­tulos, los cuales son otros componentes de su estructura de organizaciÃ³n.

### Ley de Wadler

[Ley de Wadler en wiki.haskell.org (inglÃ©s)](https://wiki.haskell.org/Wadler's_Law)

> En cualquier diseÃ±o de lenguaje, el total de tiempo invertido en discutir una caracterÃ­stica en su lista es proporcional a dos elevado a la potencia de su posiciÃ³n:
>
> 0. SemÃ¡ntica
> 1. Sintaxis
> 2. Sintaxis LÃ©xica
> 3. Sintaxis LÃ©xica de Comentarios
>
> (En pocas palabras, por cada hora invertida en semÃ¡ntica, 8 horas serÃ¡n invertidas en la sintaxis de los comentarios).

Similar a [La Ley de la Trivialidad](#ley-de-la-trivialidad), la Ley de Walder establece que cuando un se diseÃ±a un lenguaje, la cantidad de horas invertida en las estructuras del lenguaje es desproporcionadamente alta en comparaciÃ³n a la importancia de estas caracterÃ­sticas.

Vea tambiÃ©n:

- [La Ley de la Trivialidad](#ley-de-la-trivialidad)

## Principios

Los Principios son generalmente mÃ¡s propensos a ser pautas relacionadas al diseÃ±o.

### El Principio de Dilbert

[El Principio de Dilbert en Wikipedia (inglÃ©s)](https://en.wikipedia.org/wiki/Dilbert_principle)

> Las compaÃ±Ã­as tienden sistÃ©micamente a promocionar empleados incompetentes a direcciÃ³n para eliminarlos del flujo de trabajo.
>
> _Scott Adams_

Un concepto de administraciÃ³n desarrollado por Scott Adams (creador de la tira cÃ³mica de Dilbert), el Principio de Dilbert estÃ¡ inspirado por [El Principio de Peter](#el-principio-de-peter). Bajo el Principio de Dilbert, los empleados que nunca fueron competentes son promocionados a cargos directivos para limitar el daÃ±o que pueden hacer. Adams primero explicÃ³ el principio en 1995 en un artÃ­culo del Wall Street Journal y lo expandiÃ³ en su libro de negocios publicado en 1996, [The Dilbert Principle (inglÃ©s)](#lista-de-lectura).

Vea tambiÃ©n:

- [El Principio de Peter](#el-principio-de-peter)
- [Ley de Putt](#ley-de-putt)

### El Principio de Pareto (La Regla 80/20)

[El Principio de Pareto en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_Pareto)

> La mayorÃ­a de cosas en la vida no se distribuyen de forma uniforme.

El Principio de Pareto sugiere que en algunos casos, la mayorÃ­a de los resultados vienen de la minorÃ­a de entradas:

- El 80% de un cierto trozo de software puede ser escrito con el 20% del total de tiempo asignado (a la inversa, el 20% del cÃ³digo mÃ¡s difÃ­cil toma el 80% del tiempo).
- El 20% del esfuerzo produce el 80% del resultado
- El 20% del trabajo crea el 80% de los ingresos
- El 20% de los fallos causa el 80% de los problemas
- El 20% de las caracterÃ­sticas se emplean 80% mÃ¡s que el resto

En los aÃ±os 1940s el ingeniero americano-romanÃ­ Dr. Joseph Juran, quien es ampliamente reconocido por atribuÃ­rsele ser el padre del control de calidad, [comenzÃ³ a aplicar el principio de Pareto a problemas de calidad](https://es.wikipedia.org/wiki/Joseph_Juran).

Este principio es tambiÃ©n conocido como: La Regla 80/20, La Ley de los Pocos Vitales y el Principio del Factor de Escasez.

Ejemplos del Mundo-Real:

- En 2002 Microsoft reportÃ³ que arreglando el 20% de los errores mÃ¡s reportados, 80% de los errores relacionados y los crashes en Windows y Office habÃ­an sido eliminados ([Referencia (en inglÃ©s)](https://www.crn.com/news/security/18821726/microsofts-ceo-80-20-rule-applies-to-bugs-not-just-features.htm)).

### El Principio de Peter

[El Principio de Peter en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_Peter)

> La gente en una jerarquÃ­a tiende a ascender hasta su "nivel de incompetencia".
>
> _Laurence J. Peter_

Un concepto de administraciÃ³n de Laurence J. Peter, el Principio de Peter observa que la gente que es buena en sus trabajos es promocionada hasta llegar a un nivel donde ya no son tan exitosos (su "nivel de incompetencia"). En este punto, como ellos son mÃ¡s _senior_, son menos propensos a ser eliminados de la organizaciÃ³n (a menos que su rendimiento sea espectacularmente malo) y continuarÃ¡n en un rol en el que tienen pocas habilidades intrÃ­nsecas. Las habilidades que les hicieron exitosos no son necesariamente las habilidades requeridas para sus nuevos puestos.

Este es de particular interÃ©s para los ingenieros - quienes inicialmente comienzan en roles profundamente tÃ©cnicos, pero a veces tienen una carrera la cual les guÃ­a a _administrar_ a otros ingenieros - los cuales requieren un conjunto fundamentalmente diferente de habilidades.

Vea tambiÃ©n:

- [El Principio de Dilbert](#el-principio-de-dilbert)
- [La Ley de Putt](#ley-de-putt)

### El Principio de Robustez (Ley de Postel)

[El Principio de Robustez en Wikipedia (inglÃ©s)](https://en.wikipedia.org/wiki/Robustness_principle)

> SÃ© conservador en lo que haces y liberal con lo que recibes de otros.

A veces aplicado en desarrollo de aplicaciones de servidor, este principio establece que lo que tÃº envias a otros debe ser tan mÃ­nimo y consensuado como sea posible, pero lo que deberÃ­as tener como objetivo es permitir la entrada no consensuada si es que puede ser procesada.

El objetivo de este principio es construir sistemas los cuales sean robustos, tanto que puedan manejar entradas algo deficientes si aÃºn pueden ser entendidas. Sin embargo, hay potenciales implicaciones de seguridad acerca de aceptar entradas mal formadas, particularmente si el procesamiento de tales entradas no ha sido bien testeado.

### SOLID

Este es un acrÃ³nimo el cual se refiere a:

* S: [El Principio de Responsabilidad Ãšnica](#principio-de-responsabilidad-unica) (S por _Single Responsability_ del inglÃ©s)
* O: [El Principio Abierto/Cerrado](#principio-abierto-cerrado) (O por _Open/Close_)
* L: [El Principio de SustituciÃ³n de Liskov](#principio-de-sustitucion-de-liskov) (L por _Liskov_)
* I: [El Principio de SegregaciÃ³n de Interfaces](#principio-de-segregacion-de-interfaces) (I por _Interfaces Segregation_)
* D: [El Principio de InversiÃ³n de Dependencia](#principio-de-inversion-de-dependencia)

Estos son los principios clave en la [ProgramaciÃ³n Orientada a Objetos](#por-hacer). Los principios de diseÃ±o tales como estos deben servir de ayuda a desarrolladores para construir sistemas mÃ¡s mantenibles.

### Principio de Responsabilidad Ãšnica

[El Principio de Responsabilidad Ãšnica en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_responsabilidad_%C3%BAnica)

> Cada mÃ³dulo o clase debe tener una tan solo una Ãºnica responsabilidad.

El primero de los principios '[SOLID](#solid)'. Este principio sugiere que los mÃ³dulos o clases deben hacer una Ãºnica cosa y solo una. En tÃ©rminos mÃ¡s prÃ¡cticos, esto quire decir que una Ãºnico, pequeÃ±o cambio a una caracterÃ­stica de un programa debe requerir un cambio en un solo componente. Por ejemplo, cambiar como una contraseÃ±a es validada por complejidad debe requerir un cambio en solo una parte del programa.

TeÃ³ricamente, esto debe hacer el cÃ³digo mÃ¡s robusto (sÃ³lido) y fÃ¡cil de cambiar. Sabiendo que un componente el cual estÃ¡ siendo modificado tiene una Ãºnica responsabilidad sÃ³lo significa que _comprobar_ ese cambio dede ser mÃ¡s fÃ¡cil. Usando el ejemplo anterior, cambiar el componente de complejidad de la contraseÃ±a debe solo afectar a las caracterÃ­sticas relacionadas con la complejidad de la contraseÃ±a. Puede ser mucho mÃ¡s difÃ­cil tener en cuenta el impacto de un cambio en un componente el cual tiene muchas responsabilidades.

Vea tambiÃ©n:

- [ProgramaciÃ³n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)

### Principio de Abierto/Cerrado

[Principio de Abierto/Cerrado](https://es.wikipedia.org/wiki/Principio_de_abierto/cerrado)

> Las entidades deben estar abiertas para ser extendidas y cerradas para ser modificadas.

El segundo de los principios '[SOLID](#solid). Este principio establece que las entidades (las cuales pueden ser clases, mÃ³dulos, funciones u otras similares) deben tener la capacidad para ser _extendidas_ (ampliadas), pero de la misma forma debe _existir_ en su comportamiento la capacidad de no ser modificadas.

Como un ejemplo hipotÃ©tico, imagina un mÃ³dulo el cual es capaz de convertir un documento Markdown en uno HTML. Si el mÃ³dulo puede ser ampliado para manejar nuevas caracterÃ­sticas de Markdown, sin modificar el funcionamiento interno del mÃ³dulo, entonces podemos decir que estÃ¡ abierto para ser ampliado para su extensiÃ³n. Si el mÃ³dulo _no_ pudiera ser modificado por un consumidor de manera que se manejen las caracterÃ­sticas existentes de Markdown, entonces se_cierra_ para su modificaciÃ³n.

Este principio tiene una relevancia particular para la programaciÃ³n orientada a objetos, donde el diseÃ±o de objetos puede ser extendido (a travÃ©s de la herencia), pero evitarÃ­amos diseÃ±ar objetos los cuales puedan cambiar su comportamiento existente de formas inesperadas.

Vea tambiÃ©n:

- [ProgramaciÃ³n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)

### Principio de SustituciÃ³n de Liskov

[El Principio de SustituciÃ³n de Liskov en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_sustituci%C3%B3n_de_Liskov)

> Debe ser posible reemplazar un tipo con un subtipo, sin romper el sistema.

El tercero de los principios '[SOLID](#solid)'. Este principio establece que si un componente se basa en un tipo, entonces debe ser capaz de usar subtipos de ese tipo, sin que el sistema falle o tenga constancia de los detalles de que es un subtipo.

Como un ejemplo, imagina que tenemos un mÃ©todo el cual lee un documento XML desde una estructura la cual representa un fichero. Si el mÃ©todo usa un tipo base 'fichero', entonces cualquiera que derive de 'fichero' debe ser capaz de ser usado en la funciÃ³n. Si 'fichero' soporta la bÃºsqueda inversa, y el parseador de XML usa esa funciÃ³n, y entonces el tipo derivado 'fichero de red' falla cuando intenta una bÃºsqueda inversa, el tipo derivado 'fichero de red' violarÃ­a el principio.

Este principio tiene particular relevancia en programaciÃ³n orientada a objetos, donde la jerarquÃ­a de tipos debe ser modelada con cuidado para evitar confundir a los usuarios de un sistema.

Vea tambiÃ©n:

- [ProgramaciÃ³n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)

### Principio de SegregaciÃ³n de Interfaces

[El Principio de la SegregaciÃ³n de Interfaces en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_segregaci%C3%B3n_de_la_interfaz)

> NingÃºn cliente debe ser forzado a depender de mÃ©todos que no use.

El cuarto de los principios de '[SOLID](#solid)'. Este principio establece que los consumidores de un componente no deben depender en funciones de ese componente que no estÃ©n empleando.

Como un ejemplo, imagina que tenemos un mÃ©todo el cual lee un documento XML de una estructura la cual representa un fichero. Este solo necesita leer bytes, moverse adelante y atrÃ¡s en el fichero. Si este mÃ©todo necesita ser actualizado porque una caracterÃ­stica no relacionada al fichero cambia (tal como una actualizaciÃ³n al modelo de permisos usado para representar la seguridad del fichero), entonces el principio queda invalidado. SerÃ­a mejor para el fichero implementar una interfaz 'flujo-con-bÃºsqueda' y emplearla para el lector XML.

El principio tiene particular relevancia en programaciÃ³n orientada a objetos, donde las interfaces, jerarquÃ­as y abstracciones de tipos son usados para [minimizar el acoplamiento](#por-hacer) entre los diferentes componentes. [La tipificaciÃ³n dinÃ¡mica](#por-hacer) (mÃ¡s conocida como _Duck typing_ en inglÃ©s) es una metodologÃ­a que fuerza este principio eliminando las interfaces explÃ­citas.

Vea tambiÃ©n:

- [ProgramaciÃ³n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)
- [TipificaciÃ³n dinÃ¡mica](#por-hacer) (_Duck typing_)
- [Desacoplado](#por-hacer)

### Principio de InversiÃ³n de Dependencia

[El Principio de InversiÃ³n de Dependencia en Wikipedia (inglÃ©s)](https://en.wikipedia.org/wiki/Dependency_inversion_principle)

> MÃ³dulos de alto-nivel no deben depender en implementaciones de bajo nivel.

El quinto de los principios '[SOLID](#solid)'. Este principio establece que la orquestaciÃ³n de componentes del mÃ¡s alto nivel deben no tener conocimiento de los detalles de sus dependencias.

Como un ejemplo, imagina que tenemos un programa que lee metadatos de un sitio web. Asumimos que el componente principal pueda tener que saber acerca de un componente de descarga del contenido de la pÃ¡gina web y luego un componente que pueda leer los metadatos. Si tenemos la inversiÃ³n de dependenicas en mente, el componente principal dependerÃ¡ solo de un componente abstracto el cual obtendrÃ¡ los bytes de datos y luego un componente abstracto que serÃ¡ capaz de leer los metadatos del flujo de bytes. El componente principal no sabrÃ¡ nada acerca de TCP/IP, HTTP, HTML, etc.

Este principio es complejo, puede ser visto como 'inverso' a las dependencias esperadas de un sistema (de ahÃ­ el nombre). En la prÃ¡ctica, esto tambiÃ©n significa que se separa la orquestaciÃ³n de un componente y debe asegurarse la implementaciÃ³n correcta de los tipos abstractos que son empleados (e.g. en el ejemplo anterior, _algo_ debe aÃºn proporcionar el componente de lectura de los metadatos un descargador de ficheros HTTP y un lector de etiquetas meta de HTML). Este entonces toca patrones tales como [InversiÃ³n de Control](#por-hacer) y [InyecciÃ³n de Dependencias](#por-hacer).

Vea tambiÃ©n:

- [ProgramaciÃ³n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)
- [InversiÃ³n de Control](#por-hacer)
- [InyecciÃ³n de Dependencias](#por-hacer)

### Principio DRY

[El Principio DRY en Wikipedia](https://es.wikipedia.org/wiki/No_te_repitas)

> Cada pieza de conocimiento debe tener una representaciÃ³n Ãºnica, no ambigua y autoritaria dentro de un sistema.

DRY es el acrÃ³nimo en inglÃ©s para _Don't Repeat Yourself_ (No te repitas). Este principio se enfoca en ayudar a los desarrolladores a reducir las repeticiones de cÃ³digo y mantener la informaciÃ³n en un Ãºnico lugar y fue citado en 1999 por Andrew Hunt y Dave Thomas en el libro [The Pragmatic Developer](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer) (El Desarrollador PragmÃ¡tico).

> Lo contrario a DRY serÃ­a _WET_ (Write Everthing Twice, escribe todo dos veces o We Enjoy Typing, disfrutamos escribiendo)

En la prÃ¡ctica, si tienes el mismo trozo de informaciÃ³n en dos (o mÃ¡s) sitios diferentes, puedes usar DRY para mezclarlo en uno solo y reusarlo en cualquier lugar que lo quieras/necesites.

Vea tambiÃ©n:

- [The Pragmatic Developer](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer)

### Principio KISS

[KISS en Wikipedia](https://es.wikipedia.org/wiki/Principio_KISS)

> Keep it simple, stupid (Mantenlo simple, estÃºpido)

El principio KISS establece que la mayorÃ­a de los sistemas funcionan mejor si se mantienen simples en lugar de complejos; por lo tanto, simplicidad debe ser el objetivo clave en el diseÃ±o y la complejidad innecesaria debe ser evitada. Originado en las fuerzas armadas de los Estados Unidos (U.S. Navy) en 1960, la frase ha sido asociada con la ingeniera aÃ©rea Kelly Johnson.

El principio es mejor ejemplificado por la historia de Johnson manejando un equipo de ingenieros de diseÃ±o de herramientas, con el desafÃ­o del jet aircraft ellos debÃ­an diseÃ±ar sobretodo que fuese reparable por un mecÃ¡nico medio en el campo y en condiciones de combate con solo esas herramientas. De aquÃ­ el "estÃºpido" refiriÃ©ndose a la relaciÃ³n entre la forma en que las cosas se rompen y la sofisticaciÃ³n de las herramientas disponibles para repararlas, no las capacidades de los ingenieros en sÃ­ mismos.

Vea tambiÃ©n:

- [Ley de Gall](#ley-de-gall)

### YAGNI

[YAGNI en Wikipedia](https://es.wikipedia.org/wiki/YAGNI)

Este es un acrÃ³nimo para (en inglÃ©s) _**Y**ou **A**ren't **G**onna **N**eed **I**t_ o _No vas a necesitarlo_.

> Siempre implementar cosas cuando vayas a necesitarlas realmente, nunca cuando preveas que las necesitarÃ¡s.
>
> ([Ron Jeffries](https://twitter.com/RonJeffries)) (XP co-fundador y autor del libro "Extreme Programming Installed")

Este principio de _Extreme Programming_ (XP) sugiere a los desarrolladores que deben solo implementar funcionalidad que es necesaria para los requisitos inmediatos y evitar los intentos de predecir el futuro implementando funcionalidades que podrÃ­an necesitarse luego.

Adherirse a este principio debe reducir la cantidad de cÃ³digo sin usar en la base de cÃ³digo y evitar tiempo y esfuerzo de ser malgastado en funcionalidades que no aportan valor.

Vea tambiÃ©n:

- [Lista de lectura: Extreme Programming Installed](#lista-de-lectura)


## Lista de Lectura

Si has encontrado estos conceptos interesantes, puede que disfrutes estos libros:

- [Extreme Programming Installed - Ron Jeffries, Ann Anderson, Chet Hendrikson](https://www.goodreads.com/en/book/show/67834) - Covers the core principles of Extreme Programming.
- [El MÃ­tico Hombre Mes](https://es.wikipedia.org/wiki/El_M%C3%ADtico_Hombre-Mes) - [The Mythical Man Month - Frederick P. Brooks Jr.](https://www.goodreads.com/book/show/13629.The_Mythical_Man_Month) - A classic volume on software engineering. [Brooks' Law](#brooks-law) is a central theme of the book.
- [GÃ¶del, Escher, Bach: An Eternal Golden Braid - Douglas R. Hofstadter.](https://www.goodreads.com/book/show/24113.G_del_Escher_Bach) - This book is difficult to classify. [Hofstadter's Law](#hofstadters-law) is from the book.
- [The Dilbert Principle - Adam Scott](https://www.goodreads.com/book/show/85574.The_Dilbert_Principle) - A comic look at corporate America, from the author who created the [Dilbert Principle](#the-dilbert-principl).
- [The Peter Principle - Lawrence J. Peter](https://www.goodreads.com/book/show/890728.The_Peter_Principle) - Another comic look at the challenges of larger organisations and people management, the source of [The Peter Principle](#the-peter-principle).

## Por Hacer

Â¡Hola! Si llegaste aquÃ­ es porque hiciste clic en un enlace a un tema que aÃºn no ha sido escrito, perdÃ³n por eso, Â¡este es aÃºn un trabajo en proceso!

SÃ© libre de [Abrir un _Issue_](https://github.com/manuel-rubio/hacker-laws/issues) para solicitar mÃ¡s detalles, o [abre una peticiÃ³n de cambio (_pull request_)](https://github.com/manuel-rubio/hacker-laws/pulls) para enviar tus definiciones propuestas acerca del asunto.
