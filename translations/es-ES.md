# üíªüìñ hacker-laws

Leyes, Teor√≠as, Principios y Patrones que los desarrolladores encontrar√°n √∫tiles.

- üá®üá≥ [‰∏≠Êñá / Versi√≥n China](https://github.com/nusr/hacker-laws-zh) - thanks [Steve Xu](https://github.com/nusr)!
- üáÆüáπ [Traduzione in Italiano](https://github.com/csparpa/hacker-laws-it) - grazie [Claudio Sparpaglione](https://github.com/csparpa)!
- üá∞üá∑ [ÌïúÍµ≠Ïñ¥ / Versi√≥n Koreana](https://github.com/codeanddonuts/hacker-laws-kr) - thanks [Doughnut](https://github.com/codeanddonuts)!
- üá∑üá∫ [–†—É—Å—Å–∫–∞—è –≤–µ—Ä—Å–∏—è / Versi√≥n Rusa](https://github.com/solarrust/hacker-laws) - thanks [Alena Batitskaya](https://github.com/solarrust)!
- üáπüá∑ [T√ºrk√ße / Versi√≥n Turca](https://github.com/umutphp/hacker-laws-tr) - thanks [Umut I≈üƒ±k](https://github.com/umutphp)
- üáßüá∑ [Brasileiro / Versi√≥n Brasile√±a](./translations/pt-BR.md) - thanks [Leonardo Costa](https://github.com/LeoFC97)
- üá∫üá∏ [Original English Version - Versi√≥n Original en Ingl√©s](https://github.com/dwmkerr/hacker-laws) - grazie [Dave Kerr](https://github.com/dwmkerr)!

¬øTe gusta este proyecto? Por favor, considera [Esponsorizarme](https://github.com/sponsors/dwmkerr)!

---

<!-- vim-markdown-toc GFM -->

* [Introducci√≥n](#introduccion)
* [Leyes](#leyes)
    * [Ley de Amdahl](#ley-de-amdahl)
    * [Ley de Brooks](#ley-de-brooks)
    * [Ley de Conway](#ley-de-conways)
    * [Ley de Cunningham](#ley-de-cunningham)
    * [N√∫mero de Dunbar](#numero-de-dunbar)
    * [Ley de Gall](#ley-de-gall)
    * [Cuchilla de Hanlon](#cuchilla-de-hanlon)
    * [Ley de Hofstadter](#ley-de-hofstadter)
    * [Ley de Hutber](#ley-de-hutber)
    * [El Ciclo de Sobreexpectaci√≥n y la Ley de Amara](#el-ciclo-de-sobreexpectacion-y-la-ley-de-amara)
    * [Ley de Hyrum (La Ley de las Interfaces Impl√≠citas)](#ley-de-hyrum-la-ley-de-las-interfaces-implicitas)
    * [Ley de Metcalfe](#ley-de-metcalfe)
    * [Ley de Moore](#ley-de-moore)
    * [Ley de Murphy / Ley de Sod](#ley-de-murphy--ley-de-sod)
    * [Ley de Parkinson](#ley-de-parkinson)
    * [Efecto de Optimizaci√≥n Prematura](#efecto-de-optimizacion-prematura)
    * [Ley de Putt](#ley-de-putt)
    * [Ley de Reed](#ley-de-reed)
    * [Ley de Conservaci√≥n de Complejidad (Ley de Tesler)](#ley-de-conservacion-de-complejidad-ley-de-tesler)
    * [Ley de Abstracciones Permeables](#ley-de-abstracciones-permeables)
    * [Ley de la Trivialidad](#ley-de-la-trivialidad)
    * [Filosof√≠a Unix](#filosofia-unix)
    * [El Modelo Spotify](#el-modelo-spotify)
    * [Ley de Wadler](#ley-de-wadler)
* [Principios](#principios)
    * [El Principio de Dilbert](#el-principio-de-dilbert)
    * [El Principio de Pareto (La Regla 80/20)](#el-principio-de-pareto-la-regla-8020)
    * [El Principio de Peter](#el-principio-de-peter)
    * [El Principio de la Robustez (Ley de Postel)](#el-principio-de-la-robustez-ley-de-postel)
    * [SOLID](#solid)
    * [El Principio de √önica Responsabilidad](#el-principio-de-unica-responsabilidad)
    * [El Principio Abierto/Cerrado](#el-principio-abierto-cerrado)
    * [El Principio de Sustituci√≥n de Liskov](#el-principio-de-sustitucion-de-liskov)
    * [El Principio de Segregaci√≥n de Interfaz](#el-principio-de-segregacion-de-interfaz)
    * [El Principio de Inversi√≥n de Dependencia](#el-principio-de-inversion-de-dependencia)
    * [El Principio DRY](#el-principio-dry)
    * [El Principio KISS](#el-principio-kiss)
    * [YAGNI](#yagni)
* [Lista de Lectura](#lista-de-lectura)
* [POR-HACER](#por-hacer)

<!-- vim-markdown-toc -->

## Introducci√≥n

Hay montones de leyes que la gente discute cuando habla sobre desarrollo. Este repositorio es una referencia y un resumen de algunos de los m√°s conocidos. Por favor, ¬°comparte y sube tus PRs!

‚ùó: Este repositorio contiene una explicaci√≥n sobre algunas leyes, principios y patrones, pero no _defendemos_ ninguno de ellos. Si estos pueden ser aplicados o no siempre ser√° materia de debate y muy dependiente de en qu√© est√©s trabajando.

## Leyes

¬°Y aqu√≠ vamos!

### Ley de Amdahl

[Ley de Amdahl en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Amdahl)

> La ley de Amdahl se puede interpretar de manera m√°s t√©cnica, pero en t√©rminos simples, significa que es el algoritmo el que decide la mejora de velocidad, no el n√∫mero de procesadores. Finalmente se llega a un momento que no se puede paralelizar m√°s el algoritmo.

Mejor lo ilustramos con un ejemplo. Si un programa se compone de dos partes, la parte A debe ser ejecutada en un solo procesador y la parte B puede ser paralelizada, entonces vemos que agregamos m√∫ltiples procesadores al sistema en ejecuci√≥n ese programa puede solo tener un beneficio limitado. Este puede potencialmente mejorar mucho la velocidad de la parte B - pero la velocidad de la parte A se mantendr√° sin cambios.

El diagrama de abajo muestra algunos ejemplos de mejoras potenciales en velocidad:

![Diagram: Amdahl's Law](./images/amdahls_law.png)

*(Imagen de Referencia: Por Daniels220 en Wikipedia, Creative Commons Attribution-Share Alike 3.0 Unported, https://en.wikipedia.org/wiki/File:AmdahlsLaw.svg)*

Como podemos ver, incluso un programa el cual es un 50% paralelizable se beneficiar√° muy poco m√°s all√° de 10 unidades de procesamiento, mientras que un programa el cual es 95% paralelizable todav√≠a puede alcanzar mejoras significativas de velocidad con m√°s de mil unidades de procesamiento.

A medida que la [Ley de Moore](#ley-de-moore) se ralentiza y la aceleraci√≥n de la velocidad del procesador individual disminuye, la paralelizaci√≥n es la clave para incrementar el rendimiento.La programaci√≥n de gr√°ficos es un excelente ejemplo: con la inform√°tica moderna basada en Shader, p√≠xeles individuales o fragmentos pueden ser renderizados en paralelo. Este es el porqu√© las tarjetas gr√°ficas modernas en ocasiones disponen de miles de n√∫cleos de procesamiento (GPUs o Unidades de Shader).

Vea tambi√©n:

- [Ley de Brooks](#ley-de-brooks)
- [Ley de Moore](#ley-de-moore)

### Ley de Brooks

[Ley de Brooks en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Brooks)

> Cuando se incorpora una persona en un proyecto, √©ste se ralentiza en lugar de acelerarse. Brooks tambi√©n afirm√≥ que "Nueve mujeres no pueden tener un beb√© en un mes".

Esta ley sugiere que en muchos casos, intentar acelerar la entrega de un proyecto el cual ya va tarde, agregando m√°s personas, har√° que la entrega vaya a√∫n m√°s tarde. Brooks clarifica que esto es una simplificaci√≥n, sin embargo, el razonamiento general es que el tiempo de aceleraci√≥n de nuevos recursos y la sobrecarga de comunicaci√≥n, en el inmediato corto plazo hace que la velocidad caiga. Tambi√©n, muchas tareas pueden no ser divisibles, es decir que pueden no ser f√°cilmente distribuibles entre m√°s personas, significando que el potencial incremento de velocidad es incluso menor.

La frase com√∫n en entregas "Nueve mujeres no pueden tener un beb√© en un mes" est√° relacionada a la Ley de Brooks, en particular, al hecho de que algunos tipos de trabajos no son divisibles ni paralelizables.

Este es el tema central del libro '[El M√≠tico Hombre Mes](#lista-de-lectura)'.

Vea tambi√©n:

- [Marcha de la Muerte](#todo)
- [Lista de Lectura: El M√≠tico Hombre Mes](#reading-list)

### Ley de Conway

[La Ley de Conway en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Conway)

Esta ley sugiere que los l√≠mites t√©cnicos de un sistema reflejan la estructura de la organizaci√≥n. Es com√∫nmente referido a cuando se observan mejoras de una organizaci√≥n, la Ley de Conway sugiere que si una organizaci√≥n es estructurada en muchas unidades peque√±as y desconectadas, el software que producir√° ser√° as√≠. Si una organizaci√≥n es constru√≠da m√°s entorno a soluciones 'verticales' las cuales est√°n orientadas alrededor de caracter√≠sticas o servicios, los sistemas de software tambi√©n reflejar√°n esto.

Vea tambi√©n:

- [El Modelo Spotify](#el-modelo-spotify)

### Ley de Cunningham

[Ley de Cunningham en Wikipedia](https://meta.wikimedia.org/wiki/Cunningham%27s_Law/es)

> La mejor forma de obtener la respuesta correcta en Internet no es hacer una pregunta, es enviar la respuesta err√≥nea.

Acorde a Steven McGeady, Ward Cunningham le aconsej√≥ a principios de los 80: "La mejor forma de obtener la respuesta correcta en Internet no es hacer una pregunta, es enviar una respuesta incorrecta." McGeady lo llam√≥ la Ley de Cunningham, sin embargo Cunningham niega su propiedad diciendo que es una cita err√≥nea. Aunque originalmente se refiere a las interacciones en Usenet, la ley ha sido usada para describir como otras comunidades online funcionan (e.g., Wikipedia, Reddit, Twitter, Facebook).

Vea tambi√©n:

- [XKCD 386: "Duty Calls" (El Deber Llama)](https://xkcd.com/386/)

### El N√∫mero de Dunbar

[El N√∫mero de Dunbar en Wikipedia](https://es.wikipedia.org/wiki/N%C3%BAmero_de_Dunbar)

"El n√∫mero de Dunbar es un l√≠mite cognitivo sugerido sobre el n√∫mero de personas con las que puedes mantener relaciones sociables estables- relaciones en las que un individuo sabe quien es la otra persona and c√≥mo cada persona se relaciona con cada una de las otras personas." Hay alg√∫n desacuerdo sobre el n√∫mero exacto. "... [Dunbar] propuso que los humanos pueden mantener c√≥modamente solo 150 relaciones estables." El puso el n√∫mero dentro de un contexto m√°s social, "el n√∫mero de personas con las que no sentir√≠as verg√ºenza de invitarlas a tomar una copa
"Dunbar's number is a suggested cognitive limit to the number of people with whom one can maintain stable social relationships‚Äî relationships in which an individual knows who each person is and how each person relates to every other person." There is some disagreement to the exact number. "... [Dunbar] proposed that humans can comfortably maintain only 150 stable relationships." He put the number into a more social context, "la cantidad de personas de las que no te sentir√≠as avergonzado por unirte sin invitaci√≥n a tomar una copa si te topas con ellas en un bar." Estima que el n√∫mero puede rondar generalmente entre 100 y 250.

Al igual que relaciones estables entre individuos, la relaci√≥n de un desarrollador con su c√≥digo base toma esfuerzo mantenerla. Cuando afrontas un gran n√∫mero de proyectos complicados o creas muchos proyectos, nos apoyamos en convenciones, pol√≠ticas y modelamos procedimientos para escalar. El n√∫mero de Dunbar no es solo importante para tener en mente como una oficina crece, tambi√©n cuando configuramos el alcance de los esfuerzos de un equipo o decidimos cuando debemos invertir en herramientas para asistir en el modelado y automatizar el sobregasto log√≠stico. Poniendo el n√∫mero en el contexto de ingenier√≠a, es el n√∫mero de proyectos (o complejidad normalizada de un √∫nico proyecto) para los cuales podr√≠as sentirte seguro de unirte para las rondas de soporte telef√≥nico.

Vea tambi√©n:

- [Ley de Conway](#ley-de-conway)

### Ley de Gall

[Ley de Gall en Wikipedia (ingl√©s)](https://en.wikipedia.org/wiki/John_Gall_(author)#Gall's_law)

> Un sistema complejo que funciona ha sido evolucionado invariablemente desde un sistema simple que funcionaba. Un sistema complejo dise√±ado desde cero nunca funcionar√° y no puede ser arreglado para que funcione. Tienes que comenzar de nuevo con un sistema simple que funcione.
>
> ([John Gall](https://en.wikipedia.org/wiki/John_Gall_(author)))


La Ley de Gall implica que los intentos de _dise√±ar_ un sistema altamente complejo tender√°n siempre a fallar. Sistemas altamente complejos son raramente construidos de una sola vez, estos suelen ser evoluciones de sistemas mucho m√°s simples.

El ejemplo cl√°sico es la World Wide Web (WWW). En su estado actual, es un sistema altamente complejo. Sin embargo, esta fue definida inicialmente como una forma simple de compartir contenido entre instituciones acad√©micas. Esta fue un √©xito cumpliendo sus objetivos y evolucion√≥ para llegar a ser m√°s compleja con el tiempo.

Vea tambi√©n:

- [KISS (Keep It Simple, Stupid)](#el-principio-kiss)

### La Navaja de Hanlon

[La Navaja de Hanlon en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_Hanlon)

> Nunca atribuyas a la malicia lo que puede ser adecuadamente explicado por la estupidez.
>
> Robert J. Hanlon

Este principio sugiere que las acciones resultantes en un resultado negativo no fueron resultado de una mala intenci√≥n. En su lugar el resultado negativo es mejor atribu√≠do a que esas acciones y/o el impacto no fueron completamente entendidos.

### Ley de Hofstadter

[Ley de Hofstadter en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Hofstadter)

> Siempre lleva m√°s tiempo de lo que esperas, incluso si tienes en cuenta la Ley de Hofstadter.
>
> (Douglas Hofstadter)

Quiz√°s hayas o√≠do esta ley referida a cuando se busca estimar el tiempo que tomar√° algo. Esto parece una verdad absoluta en el desarrollo de software donde tendemos a no ser muy buenos estimando con precisi√≥n cuanto tiempo tomar√° entregar algo.

Esto proviene del libro '[G√∂del, Escher, Bach: An Eternal Golden Braid](#lista-de-lectura)'.

Vea tambi√©n:

- [Lista de lectura: G√∂del, Escher, Bach: An Eternal Golden Braid](#lista-de-lectura)

### Ley de Hutber

[Ley de Hutber en Wikipedia (ingl√©s)](https://en.wikipedia.org/wiki/Hutber%27s_law)

> Mejorar signfica deteriorar.
>
> ([Patrick Hutber (ingl√©s)](https://en.wikipedia.org/wiki/Patrick_Hutber))

Esta ley sugiere que las mejoras realizadas en un sistema llevar√°n a su deterioro en otras partes, u ocultar√° otros deterioros, llevando a una degradaci√≥n total del estado actual del sistema.

Por ejemplo, un decremento en la latencia de respuesta para un end-point particular podr√≠a causar problemas de rendimiento y capacidad de procesamiento m√°s adelante en el flujo de peticiones, afectando a un subsistema completamente diferente.

### El Ciclo de Sobreexpectaci√≥n y La Ley de Amara

[El Ciclo de Sobreexpectaci√≥n](https://es.wikipedia.org/wiki/Ciclo_de_sobreexpectaci%C3%B3n)

> Tendemos a sobreestimar el efecto de una tecnolog√≠a a corto plazo y subestimar su efecto a largo plazo.
>
> (Roy Amara)

El Ciclo de Sobreexpectaci√≥n es una representaci√≥n visual de la excitaci√≥n y desarrollo de tecnolog√≠a a lo largo del tiempo, originalmente producido por Gartner. Se explica mejor de forma visual:

![El Cico de Sobreexpectaci√≥n](./images/gartner_hype_cycle.png)

*(Referencia de Imagen: Por Jeremykemp en Wikipedia, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=10547051)*

En pocas palabras, el ciclo sugiere que hay una t√≠pica burbuja de excitaci√≥n alrededor de cada nueva tecnolog√≠a y su impacto potencial. Los equipos a veces saltan r√°pidamente a emplear estas tecnolog√≠as y a veces se encuentran a s√≠ mismos decepcionados con los resultados. Esto puede ser porque la tecnolog√≠a no es a√∫n lo suficientemente madura, o las aplicaciones del mundo real no est√°n completamente desarrolladas. Despu√©s de cierto tiempo, las capacidades de la tecnolog√≠a se incrementan y las oportunidades de ser empleada de forma pr√°ctica aumentan permitiendo a los equipos ser finalmente productivos. La frase de Roy Amara resume este hecho de forma breve - "Tendemos a sobreestimar el efecto de una tecnolog√≠a a corto plazo y subestimarla a largo plazo".

### Ley de Hyrum (La Ley de las Interfaces Impl√≠citas)

[Ley de Hyrum (ingl√©s)](http://www.hyrumslaw.com/)

> Con un n√∫mero suficiente de usuarios de una API,
> no importa que prometas en el contrato:
> alguien depender√° de todos los comportamientos observables
> de tu sistema.
>
> (Hyrum Wright)

La Ley de Hyrum establece que cuando tienes un _n√∫mero grande y suficiente de consumidores_ de una API, todos los comportamientos de la API (incluso aquellos no definidos como parte del contrato p√∫blico) llegar√°n de forma eventual a ser dependencia de alguien. Un ejemplo trivial pueden ser los elementos no-funcionales como el tiempo de respuesta de una API. Un ejemplo m√°s sutil puede ser qu√© consumidores est√°n dependiendo en la aplicaci√≥n de una expresi√≥n regular sobre un mensaje de error para determinar el *tipo* de error de una API. Incluso si el contrato p√∫blico de la API no establece nada acerca del contenido del mensaje de error indicando a los usuarios que deben emplear un c√≥digo de error, _algunos_ usuarios usar√°n el mensaje y cambiar el mensaje esencialmente romper√° la API para estos usuarios.

Vea tambi√©n:

- [La Ley de las Abstracciones Permeables](#la-ley-de-las-abstracciones-permeables)
- [XKCD 1172](https://xkcd.com/1172/)


### Ley de Metcalfe

[Ley de Metcalfe en Wikipedia (ingl√©s)](https://en.wikipedia.org/wiki/Metcalfe's_law)

> En teor√≠a de redes, el n√∫mero en el que un sistema crece es aproximadamente el cuadrado del n√∫mero de usuarios de ese sistema.

Esta ley est√° basada en el n√∫mero de posibles conexiones por pares dentro de un sistema y est√° muy relacionado con [La Ley de Reed](#ley-de-reed). Odlyzko y otros han argumentado que ambas leyes (Reed y Metcalfe) exageran el valor de un sistema por no tener en cuenta los l√≠mites de la cognici√≥n humana en efectos de redes; vea [El N√∫mero de Dunbar](#numero-de-dunbar).

Vea tambi√©n:
- [Ley de Reed](#ley-de-reed)
- [N√∫mero de Dunbar](#numero-de-dunbar)

### Ley de Moore

[Ley de Moore en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Moore)

> El n√∫mero de transistores en un circuito integrado se dobla aproximadamente cada dos a√±os.

A veces empleado para ilustrar la velocidad pura a la que un semiconductor y la tecnolog√≠a de chips ha mejorado, la predicci√≥n de Moore prob√≥ ser altamente precisa desde los 70 hasta finales de la primera d√©cada de 2000. En los a√±os recientes, la tendencia ha cambiado ligeramente, parcialmente debido a [las limitaciones f√≠sicas en el grado en el que los componentes pueden ser miniaturizados (ingl√©s)](https://en.wikipedia.org/wiki/Quantum_tunnelling). Sin embargo, los avances en la paralelizaci√≥n y potencialmente los cambios revolucionarios en la tecnolog√≠a de semiconductores y computaci√≥n cu√°ntica puedan significar que la Ley de Moore contin√∫e siendo cierta en las siguientes d√©cadas.

### Ley de Murphy / Ley de Sod

[Ley de Murphy en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Murphy)

> Si algo puede ir mal, ir√° mal.

Relacionado con [Edward A. Murphy, Jr](https://es.wikipedia.org/wiki/Edward_A._Murphy_Jr.) la _Ley de Murphy_ establece que si algo puede ir mal, ir√° mal.

Este dicho es muy com√∫n entre desarrolladores. A veces algo inesperado sucede cuando se desarrolla, se hacen pruebas o incluso en producci√≥n. Esto puede relacionarse tambi√©n a la (m√°s com√∫n en ingl√©s brit√°nico) _Ley de Sod_:

> Si algo puede ir mal, ir√° mal, en el peor momento posible.

Estas leyes son generalmente empleadas en sentido c√≥mico. Sin embargo, tales fen√≥menos como la [_Sesgo de Confirmaci√≥n_](#por-hacer) y [_Sesgo de Selecci√≥n_](#por-hacer) pueden llevar a la gente a sobre-enfatizar estas leyes (la mayor√≠a de las veces cuando las cosas funcionan, estas pasan sin tenerse en cuenta, mientras que los fallos son muy notalbes y entran m√°s en las conversaciones).

Vea tambi√©n:

- [Sesgo de Confirmaci√≥n](#por-hacer)
- [Sesgo de Selecci√≥n](#por-hacer)

### Ley de Parkinson

[Ley de Parkinson en Wikipedia](https://es.wikipedia.org/wiki/Ley_de_Parkinson)

> El trabajo se expande hasta llenar el tiempo disponible para que se termine.

En su contexto original, esta Ley se bas√≥ en estudios de burocracias. Esta pod√≠a ser aplicada de forma pesimista a las iniciativas de desarrollo de software, la teor√≠a ser√≠a que los equipos ser√°n ineficientes hasta que la fecha de entrega est√© cerca, entonces se apresurar√°n a completar el trabajo para la entrega, haciendo la fecha de entrega real de alg√∫n modo arbitraria.

Si esta ley se combina con la [Ley de Hofstadter](#ley-de-hofstadter), un punto de vista incluso m√°s pesimista es alcanzado - el trabajo se expandir√° hasta rellenar el tiempo disponible para su compleci√≥n y *a√∫n tomar√° m√°s tiempo del esperado*.

Vea tambi√©n:

- [Ley de Hofstadter](#ley-de-hofstadter)

### Efecto de Optimizaci√≥n Prematura

[Optimizaci√≥n Prematura en Wikipedia](https://es.wikipedia.org/wiki/Optimizaci%C3%B3n_de_software#Cu%C3%A1ndo_optimizar)

> Debemos olvidar las peque√±as eficiencias, por ejemplo, el 97% del tiempo: la optimizaci√≥n prematura es la ra√≠z de todos los males.
>
> [(Donald Knuth, diciembre de 1974)](https://twitter.com/realdonaldknuth)

En el documento de Donald Knuth titulado [Programaci√≥n Estructurada con Mandatos Go To (ingl√©s)](http://wiki.c2.com/?StructuredProgrammingWithGoToStatements), escribi√≥: "Los programadores desperdician enormes cantidades de tiempo pensando o preocup√°ndose acerca de la velocidad de partes no-cr√≠ticas de sus programas, y esos intentos de eficiencia en realidad tienen un impacto negativo cuando consideramos la depuraci√≥n o el mantenimiento. Debemos olvidar las peque√±as eficiencias, por ejemplo, el 97% del tiempo: **la optimizaci√≥n prematura es la ra√≠z de todos los males**. Aunque no debemos dejar pasar nuestras oportunidades en ese cr√≠tico 3%."

Sin embargo, _Premature Optimization_ puede ser definido (en t√©rminos menos cargados) como nosotros sabemos lo que tenemos que hacer.

### Ley de Putt

[Ley de Putt (ingl√©s)](https://en.wikipedia.org/wiki/Putt%27s_Law_and_the_Successful_Technocrat)

> La Tecnolog√≠a es dominada por dos tipos de personas, aquellos quienes comprenden lo que no controlan y aquellos quienes controllan lo que no entienden.

La Ley de Putt a veces es seguida por el Corolario de Putt:

> Cada jerarqu√≠a t√©cnica, con el tiempo, desarrolla una inversi√≥n de competencia.

Estos mandatos sugieren que debido a varios criterios de selecci√≥n y tendencias en c√≥mo los grupos se organizan, habr√° un n√∫mero de personas cualificadas en los niveles de trabajo de una organizaci√≥n t√©cnica y una cantidad de personas en roles directivos que no son conscientes de las complejidades y desaf√≠os del trabajo que est√°n manejando. Esto puede ser debido al fen√≥menos tales como [El Principio de Peter](#el-principio-de-peter) o [El Principio de Dilbert](#el-principio-de-dilbert).

Sin embargo, debe enfatizarse que leyes como esta son generalizaciones amplias y pueden aplicarse a _algunos_ tipos de organizaciones y no a otras.

Vea tambi√©n:

- [El Principio de Peter](#el-principio-de-peter)
- [El Principio de Dilbert](#el-principio-de-dilbert)

### La Ley de Reed

[La Ley de Reed en Wikipedia (ingl√©s)](https://en.wikipedia.org/wiki/Reed's_law)

> La utilidad de redes grandes, particularmente redes sociales, escala exponencialmente con el tama√±o de la red.

Esta ley est√° basada en la teor√≠a de grafos, donde la utilidad escala como el n√∫mero de posibles sub-grupos, el cu√°l es m√°s r√°pido que el n√∫mero de participantes o el n√∫mero de posibles conexiones p
Esta ley se basa en la teor√≠a de grafos, donde la utilidad se escala como el n√∫mero de subgrupos posibles, que es m√°s r√°pido que el n√∫mero de participantes o el n√∫mero de posibles conexiones por pares. Odlyzko y otros han argumentado que la Ley de Reed exagera la utilidad del sistema al no tener en cuenta los l√≠mites de la cognici√≥n humana sobre los efectos de la red; ver [El N√∫mero de Dunbar](#numero-de-dunbar).

See also:
- [La Ley de Metcalfe's Law](#metcalfes-law)
- [N√∫mero de Dunbar](#numero-de-dunbar)

### Ley de Conservaci√≥n de Complejidad (Ley de Tesler)

[La Ley de Conservaci√≥n de Complejidad en Wikipedia (ingl√©s)](https://en.wikipedia.org/wiki/Law_of_conservation_of_complexity)

Esta ley establece que hay una cierta cantidad de complejidad en un sistema la cu√°l no puede ser reducida.

Cierta complejidad en un sistema puede ser 'involuntaria'. Es consecuencia de una estructura deficiente, errores o tan solo un mal modelo de un problema a resolver. La complejidad involuntaria puede ser reducida (o eliminada). Sin embargo, cierta complejidad es 'intr√≠nseca' como consecuencia de la complejidad inherente de un problema que se est√° resolviendo. Esta complejidad puede ser desplazada, pero no eliminada.

Un elemento interesate de esta ley es la sugerencia de que incluso simplificando el sistema entero, la complejidad intr√≠nseca no se reduce, esta se _desplaza hacia el usuario_, el cu√°l debe comportarse de una forma compleja.

### Ley de las Abstracciones Permeables

[La Ley de las Abstracciones Permeables en Joel on Software (ingl√©s)](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/)

> Toda abstracci√≥n no trivial, en alg√∫n grado, es permeable.
>
> ([Joel Spolsky](https://twitter.com/spolsky))

Esta ley establece que las abstracciones, las cuales son generalmente usadas en computaci√≥n para simplificar el trabajo con sistemas complicados, en ciertas situaciones 'filtrar√°n' sus elementos a un sistema subyacente, haciendo que la abstracci√≥n se comporte de una forma inesperada.

Un ejemplo puede ser la carga de un fichero y lectura de sus contenidos. Las APIs del sistema de ficheros son una _abstracci√≥n_ del bajo nivel de los sistemas del kernel, los cuales son en s√≠ mismos abstracciones de los procesos f√≠sicos relacionados con el cambio de informaci√≥n en un disco magn√©tico (o memoria flash para un SSD). En la mayor√≠a de los casos, funcionar√° la abstracci√≥n de tratar al fichero como un flujo de datos binarios. Sin embargo, para un disco magn√©tico, leer datos secuenciales puede ser *significativamente* m√°s r√°pido que los accesos aleatorios (debido al aumento de la sobrecarga de fallas), pero no para un disco SSD donde este aumento no estar√° presente. Los detalles subyacentes necesitar√°n ser entendidos para tratar cada caso (por ejemplo, √≠ndices de base de datos son estructurados para reducir la sobrecarga del acceso aleatorio), la abstracci√≥n 'filtra' detalles de la implementaci√≥n al desarrollador que pueda necesitar tener en cuenta.

El ejemplo anterior puede llegar a ser a√∫n m√°s complejo cuando _m√°s_ abstracciones sean introducidas. El sistema operativo Linux permite acceder a ficheros en red pero representados de forma local como ficheros 'normales'. Esta abstracci√≥n 'filtrar√°' si hay errores de red. Si un desarrollador trata estos ficheros como 'normales', sin considerar el hecho de que puedan estar sujetos a latencia de red y fallos, las soluciones ser√°n defectuosas.

El art√≠culo que describe esta ley sugiere que una dependenica excesiva de abstracciones, combinada con un entendimiento deficiente del proceso subyacente, en realidad hace que tratar con el problema sea _m√°s_ complejo en algunos casos.

Vea tambi√©n:

- [Ley de Hyrum](#ley-de-hyrum-la-ley-de-las-interfaces-implicitas)

Ejemplos del Mundo-Real:

- [Inicio lento en Photoshop (ingl√©s)](https://forums.adobe.com/thread/376152) - un problema que encontr√© en el pasado. Photoshop podr√≠a tener un inicio lento, algunas veces tomando incluso minutos. Parece que el problema fue debido a que al inicio lee cierta informaci√≥n sobre la impresora por defecto. Sin embargo, si la impresora est√° en red, esto puede tomar mucho tiempo. La _abstracci√≥n_ de una impresora en red siendo presentada al sistema de forma similar a una impresora local caus√≥ un problema para usuarios en situaciones de conectividad de red deficiente.

### Ley de la Trivialidad

[Ley de la Trivialidad en Wikipedia (ingl√©s)](https://en.wikipedia.org/wiki/Law_of_triviality)

Esta ley sugiere que los grupos invertir√°n mucho m√°s tiempo y atenci√≥n a problemas triviales y cosm√©ticos que a problemas serios y sustanciales.

El ejemplo com√∫n y ficticio usado para ilustrarlo es que un comit√© aprobando planes para una planta nuclear invertir√° la mayor parte del tiempo discutiendo la estructura del aparcamiento de bicicletas que dise√±os mucho m√°s importantes para la planta nuclear en s√≠ misma. Puede ser dif√≠cil hacer aportes valiosos en las discusiones sobre temas muy grandes y complejos sin un alto grado de experiencia y preparaci√≥n en el tema. Sin embargo, la gente quiere ser vista contribuyendo de forma valiosa. De ah√≠ la tendencia a enfocarse demasiado en detalles peque√±os, los cuales pueden ser razonados f√°cilmente, pero no necesariamente de particular importancia.

El ejemplo ficticio de arriba nos lleva al uso del t√©rmino 'Aparcamiento de Bicicletas' (Bike Shedding) como una expresi√≥n para el desperdicio del tiempo en detalles triviales.

### Filosof√≠a Unix

[La Filosof√≠a Unix en Altenwald](https://altenwald.org/2008/09/22/filosofia-unix/)

La Filosof√≠a Unix es que los componentes de software debe ser peque√±os y enfocados en hacer tan solo una cosa bien. Esto puede hacer m√°s f√°cil construir sistemas a trav√©s de la composici√≥n conjunta de peque√±as, simples y bien definidas unidades mejor que usar programas grandes, complejos y multi-prop√≥sito.

Pr√°cticas modernas como 'Arquitectura de Microservicios' pueden ser pensadas como una aplicaci√≥n de esta ley, donde los servicios son peque√±os, enfocados y hacen una cosa espec√≠fica, permitiendo componer comportamientos m√°s complejos compuestos de bloques de construcci√≥n simples.

### El Modelo Spotify

[El Modelo Spotify en Spotify Labs (ingl√©s)](https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/)

El Modelo Spotify es un enfoque a una estructura de organizaci√≥n la cual ha sido popularizada por 'Spotify'. En este modelo, los equipos son organizados alrededor de caracter√≠sticas en lugar de tecnolog√≠as.

El Modelo Spotify tambi√©n populariz√≥ los conceptos de Tribus, Gremios y Cap√≠tulos, los cuales son otros componentes de su estructura de organizaci√≥n.

### Ley de Wadler

[Ley de Wadler en wiki.haskell.org (ingl√©s)](https://wiki.haskell.org/Wadler's_Law)

> En cualquier dise√±o de lenguaje, el total de tiempo invertido en discutir una caracter√≠stica en su lista es proporcional a dos elevado a la potencia de su posici√≥n:
>
> 0. Sem√°ntica
> 1. Sintaxis
> 2. Sintaxis L√©xica
> 3. Sintaxis L√©xica de Comentarios
>
> (En pocas palabras, por cada hora invertida en sem√°ntica, 8 horas ser√°n invertidas en la sintaxis de los comentarios).

Similar a [La Ley de la Trivialidad](#ley-de-la-trivialidad), la Ley de Walder establece que cuando un se dise√±a un lenguaje, la cantidad de horas invertida en las estructuras del lenguaje es desproporcionadamente alta en comparaci√≥n a la importancia de estas caracter√≠sticas.

Vea tambi√©n:

- [La Ley de la Trivialidad](#ley-de-la-trivialidad)

## Principios

Los Principios son generalmente m√°s propensos a ser pautas relacionadas al dise√±o.

### El Principio de Dilbert

[El Principio de Dilbert en Wikipedia (ingl√©s)](https://en.wikipedia.org/wiki/Dilbert_principle)

> Las compa√±√≠as tienden sist√©micamente a promocionar empleados incompetentes a direcci√≥n para eliminarlos del flujo de trabajo.
>
> _Scott Adams_

Un concepto de administraci√≥n desarrollado por Scott Adams (creador de la tira c√≥mica de Dilbert), el Principio de Dilbert est√° inspirado por [El Principio de Peter](#el-principio-de-peter). Bajo el Principio de Dilbert, los empleados que nunca fueron competentes son promocionados a cargos directivos para limitar el da√±o que pueden hacer. Adams primero explic√≥ el principio en 1995 en un art√≠culo del Wall Street Journal y lo expandi√≥ en su libro de negocios publicado en 1996, [The Dilbert Principle (ingl√©s)](#lista-de-lectura).

Vea tambi√©n:

- [El Principio de Peter](#el-principio-de-peter)
- [Ley de Putt](#ley-de-putt)

### El Principio de Pareto (La Regla 80/20)

[El Principio de Pareto en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_Pareto)

> La mayor√≠a de cosas en la vida no se distribuyen de forma uniforme.

El Principio de Pareto sugiere que en algunos casos, la mayor√≠a de los resultados vienen de la minor√≠a de entradas:

- El 80% de un cierto trozo de software puede ser escrito con el 20% del total de tiempo asignado (a la inversa, el 20% del c√≥digo m√°s dif√≠cil toma el 80% del tiempo).
- El 20% del esfuerzo produce el 80% del resultado
- El 20% del trabajo crea el 80% de los ingresos
- El 20% de los fallos causa el 80% de los problemas
- El 20% de las caracter√≠sticas se emplean 80% m√°s que el resto

En los a√±os 1940s el ingeniero americano-roman√≠ Dr. Joseph Juran, quien es ampliamente reconocido por atribu√≠rsele ser el padre del control de calidad, [comenz√≥ a aplicar el principio de Pareto a problemas de calidad](https://es.wikipedia.org/wiki/Joseph_Juran).

Este principio es tambi√©n conocido como: La Regla 80/20, La Ley de los Pocos Vitales y el Principio del Factor de Escasez.

Ejemplos del Mundo-Real:

- En 2002 Microsoft report√≥ que arreglando el 20% de los errores m√°s reportados, 80% de los errores relacionados y los crashes en Windows y Office hab√≠an sido eliminados ([Referencia (en ingl√©s)](https://www.crn.com/news/security/18821726/microsofts-ceo-80-20-rule-applies-to-bugs-not-just-features.htm)).

### El Principio de Peter

[El Principio de Peter en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_Peter)

> La gente en una jerarqu√≠a tiende a ascender hasta su "nivel de incompetencia".
>
> _Laurence J. Peter_

Un concepto de administraci√≥n de Laurence J. Peter, el Principio de Peter observa que la gente que es buena en sus trabajos es promocionada hasta llegar a un nivel donde ya no son tan exitosos (su "nivel de incompetencia"). En este punto, como ellos son m√°s _senior_, son menos propensos a ser eliminados de la organizaci√≥n (a menos que su rendimiento sea espectacularmente malo) y continuar√°n en un rol en el que tienen pocas habilidades intr√≠nsecas. Las habilidades que les hicieron exitosos no son necesariamente las habilidades requeridas para sus nuevos puestos.

Este es de particular inter√©s para los ingenieros - quienes inicialmente comienzan en roles profundamente t√©cnicos, pero a veces tienen una carrera la cual les gu√≠a a _administrar_ a otros ingenieros - los cuales requieren un conjunto fundamentalmente diferente de habilidades.

Vea tambi√©n:

- [El Principio de Dilbert](#el-principio-de-dilbert)
- [La Ley de Putt](#ley-de-putt)

### El Principio de Robustez (Ley de Postel)

[El Principio de Robustez en Wikipedia (ingl√©s)](https://en.wikipedia.org/wiki/Robustness_principle)

> S√© conservador en lo que haces y liberal con lo que recibes de otros.

A veces aplicado en desarrollo de aplicaciones de servidor, este principio establece que lo que t√∫ envias a otros debe ser tan m√≠nimo y consensuado como sea posible, pero lo que deber√≠as tener como objetivo es permitir la entrada no consensuada si es que puede ser procesada.

El objetivo de este principio es construir sistemas los cuales sean robustos, tanto que puedan manejar entradas algo deficientes si a√∫n pueden ser entendidas. Sin embargo, hay potenciales implicaciones de seguridad acerca de aceptar entradas mal formadas, particularmente si el procesamiento de tales entradas no ha sido bien testeado.

### SOLID

Este es un acr√≥nimo el cual se refiere a:

* S: [El Principio de Responsabilidad √önica](#principio-de-responsabilidad-unica) (S por _Single Responsability_ del ingl√©s)
* O: [El Principio Abierto/Cerrado](#principio-abierto-cerrado) (O por _Open/Close_)
* L: [El Principio de Sustituci√≥n de Liskov](#principio-de-sustitucion-de-liskov) (L por _Liskov_)
* I: [El Principio de Segregaci√≥n de Interfaces](#principio-de-segregacion-de-interfaces) (I por _Interfaces Segregation_)
* D: [El Principio de Inversi√≥n de Dependencia](#principio-de-inversion-de-dependencia)

Estos son los principios clave en la [Programaci√≥n Orientada a Objetos](#por-hacer). Los principios de dise√±o tales como estos deben servir de ayuda a desarrolladores para construir sistemas m√°s mantenibles.

### Principio de Responsabilidad √önica

[El Principio de Responsabilidad √önica en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_responsabilidad_%C3%BAnica)

> Cada m√≥dulo o clase debe tener una tan solo una √∫nica responsabilidad.

El primero de los principios '[SOLID](#solid)'. Este principio sugiere que los m√≥dulos o clases deben hacer una √∫nica cosa y solo una. En t√©rminos m√°s pr√°cticos, esto quire decir que una √∫nico, peque√±o cambio a una caracter√≠stica de un programa debe requerir un cambio en un solo componente. Por ejemplo, cambiar como una contrase√±a es validada por complejidad debe requerir un cambio en solo una parte del programa.

Te√≥ricamente, esto debe hacer el c√≥digo m√°s robusto (s√≥lido) y f√°cil de cambiar. Sabiendo que un componente el cual est√° siendo modificado tiene una √∫nica responsabilidad s√≥lo significa que _comprobar_ ese cambio dede ser m√°s f√°cil. Usando el ejemplo anterior, cambiar el componente de complejidad de la contrase√±a debe solo afectar a las caracter√≠sticas relacionadas con la complejidad de la contrase√±a. Puede ser mucho m√°s dif√≠cil tener en cuenta el impacto de un cambio en un componente el cual tiene muchas responsabilidades.

Vea tambi√©n:

- [Programaci√≥n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)

### Principio de Abierto/Cerrado

[Principio de Abierto/Cerrado](https://es.wikipedia.org/wiki/Principio_de_abierto/cerrado)

> Las entidades deben estar abiertas para ser extendidas y cerradas para ser modificadas.

El segundo de los principios '[SOLID](#solid). Este principio establece que las entidades (las cuales pueden ser clases, m√≥dulos, funciones u otras similares) deben tener la capacidad para ser _extendidas_ (ampliadas), pero de la misma forma debe _existir_ en su comportamiento la capacidad de no ser modificadas.

Como un ejemplo hipot√©tico, imagina un m√≥dulo el cual es capaz de convertir un documento Markdown en uno HTML. Si el m√≥dulo puede ser ampliado para manejar nuevas caracter√≠sticas de Markdown, sin modificar el funcionamiento interno del m√≥dulo, entonces podemos decir que est√° abierto para ser ampliado para su extensi√≥n. Si el m√≥dulo _no_ pudiera ser modificado por un consumidor de manera que se manejen las caracter√≠sticas existentes de Markdown, entonces se_cierra_ para su modificaci√≥n.

Este principio tiene una relevancia particular para la programaci√≥n orientada a objetos, donde el dise√±o de objetos puede ser extendido (a trav√©s de la herencia), pero evitar√≠amos dise√±ar objetos los cuales puedan cambiar su comportamiento existente de formas inesperadas.

Vea tambi√©n:

- [Programaci√≥n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)

### Principio de Sustituci√≥n de Liskov

[El Principio de Sustituci√≥n de Liskov en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_sustituci%C3%B3n_de_Liskov)

> Debe ser posible reemplazar un tipo con un subtipo, sin romper el sistema.

El tercero de los principios '[SOLID](#solid)'. Este principio establece que si un componente se basa en un tipo, entonces debe ser capaz de usar subtipos de ese tipo, sin que el sistema falle o tenga constancia de los detalles de que es un subtipo.

Como un ejemplo, imagina que tenemos un m√©todo el cual lee un documento XML desde una estructura la cual representa un fichero. Si el m√©todo usa un tipo base 'fichero', entonces cualquiera que derive de 'fichero' debe ser capaz de ser usado en la funci√≥n. Si 'fichero' soporta la b√∫squeda inversa, y el parseador de XML usa esa funci√≥n, y entonces el tipo derivado 'fichero de red' falla cuando intenta una b√∫squeda inversa, el tipo derivado 'fichero de red' violar√≠a el principio.

Este principio tiene particular relevancia en programaci√≥n orientada a objetos, donde la jerarqu√≠a de tipos debe ser modelada con cuidado para evitar confundir a los usuarios de un sistema.

Vea tambi√©n:

- [Programaci√≥n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)

### Principio de Segregaci√≥n de Interfaces

[El Principio de la Segregaci√≥n de Interfaces en Wikipedia](https://es.wikipedia.org/wiki/Principio_de_segregaci%C3%B3n_de_la_interfaz)

> Ning√∫n cliente debe ser forzado a depender de m√©todos que no use.

El cuarto de los principios de '[SOLID](#solid)'. Este principio establece que los consumidores de un componente no deben depender en funciones de ese componente que no est√©n empleando.

Como un ejemplo, imagina que tenemos un m√©todo el cual lee un documento XML de una estructura la cual representa un fichero. Este solo necesita leer bytes, moverse adelante y atr√°s en el fichero. Si este m√©todo necesita ser actualizado porque una caracter√≠stica no relacionada al fichero cambia (tal como una actualizaci√≥n al modelo de permisos usado para representar la seguridad del fichero), entonces el principio queda invalidado. Ser√≠a mejor para el fichero implementar una interfaz 'flujo-con-b√∫squeda' y emplearla para el lector XML.

El principio tiene particular relevancia en programaci√≥n orientada a objetos, donde las interfaces, jerarqu√≠as y abstracciones de tipos son usados para [minimizar el acoplamiento](#por-hacer) entre los diferentes componentes. [La tipificaci√≥n din√°mica](#por-hacer) (m√°s conocida como _Duck typing_ en ingl√©s) es una metodolog√≠a que fuerza este principio eliminando las interfaces expl√≠citas.

Vea tambi√©n:

- [Programaci√≥n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)
- [Tipificaci√≥n din√°mica](#por-hacer) (_Duck typing_)
- [Desacoplado](#por-hacer)

### Principio de Inversi√≥n de Dependencia

[El Principio de Inversi√≥n de Dependencia en Wikipedia (ingl√©s)](https://en.wikipedia.org/wiki/Dependency_inversion_principle)

> M√≥dulos de alto-nivel no deben depender en implementaciones de bajo nivel.

El quinto de los principios '[SOLID](#solid)'. Este principio establece que la orquestaci√≥n de componentes del m√°s alto nivel deben no tener conocimiento de los detalles de sus dependencias.

Como un ejemplo, imagina que tenemos un programa que lee metadatos de un sitio web. Asumimos que el componente principal pueda tener que saber acerca de un componente de descarga del contenido de la p√°gina web y luego un componente que pueda leer los metadatos. Si tenemos la inversi√≥n de dependenicas en mente, el componente principal depender√° solo de un componente abstracto el cual obtendr√° los bytes de datos y luego un componente abstracto que ser√° capaz de leer los metadatos del flujo de bytes. El componente principal no sabr√° nada acerca de TCP/IP, HTTP, HTML, etc.

Este principio es complejo, puede ser visto como 'inverso' a las dependencias esperadas de un sistema (de ah√≠ el nombre). En la pr√°ctica, esto tambi√©n significa que se separa la orquestaci√≥n de un componente y debe asegurarse la implementaci√≥n correcta de los tipos abstractos que son empleados (e.g. en el ejemplo anterior, _algo_ debe a√∫n proporcionar el componente de lectura de los metadatos un descargador de ficheros HTTP y un lector de etiquetas meta de HTML). Este entonces toca patrones tales como [Inversi√≥n de Control](#por-hacer) y [Inyecci√≥n de Dependencias](#por-hacer).

Vea tambi√©n:

- [Programaci√≥n Orientada a Objetos](#por-hacer)
- [SOLID](#solid)
- [Inversi√≥n de Control](#por-hacer)
- [Inyecci√≥n de Dependencias](#por-hacer)

### Principio DRY

[El Principio DRY en Wikipedia](https://es.wikipedia.org/wiki/No_te_repitas)

> Cada pieza de conocimiento debe tener una representaci√≥n √∫nica, no ambigua y autoritaria dentro de un sistema.

DRY es el acr√≥nimo en ingl√©s para _Don't Repeat Yourself_ (No te repitas). Este principio se enfoca en ayudar a los desarrolladores a reducir las repeticiones de c√≥digo y mantener la informaci√≥n en un √∫nico lugar y fue citado en 1999 por Andrew Hunt y Dave Thomas en el libro [The Pragmatic Developer](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer) (El Desarrollador Pragm√°tico).

> Lo contrario a DRY ser√≠a _WET_ (Write Everthing Twice, escribe todo dos veces o We Enjoy Typing, disfrutamos escribiendo)

En la pr√°ctica, si tienes el mismo trozo de informaci√≥n en dos (o m√°s) sitios diferentes, puedes usar DRY para mezclarlo en uno solo y reusarlo en cualquier lugar que lo quieras/necesites.

Vea tambi√©n:

- [The Pragmatic Developer](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer)

### Principio KISS

[KISS en Wikipedia](https://es.wikipedia.org/wiki/Principio_KISS)

> Keep it simple, stupid (Mantenlo simple, est√∫pido)

El principio KISS establece que la mayor√≠a de los sistemas funcionan mejor si se mantienen simples en lugar de complejos; por lo tanto, simplicidad debe ser el objetivo clave en el dise√±o y la complejidad innecesaria debe ser evitada. Originado en las fuerzas armadas de los Estados Unidos (U.S. Navy) en 1960, la frase ha sido asociada con la ingeniera a√©rea Kelly Johnson.

El principio es mejor ejemplificado por la historia de Johnson manejando un equipo de ingenieros de dise√±o de herramientas, con el desaf√≠o del jet aircraft ellos deb√≠an dise√±ar sobretodo que fuese reparable por un mec√°nico medio en el campo y en condiciones de combate con solo esas herramientas. De aqu√≠ el "est√∫pido" refiri√©ndose a la relaci√≥n entre la forma en que las cosas se rompen y la sofisticaci√≥n de las herramientas disponibles para repararlas, no las capacidades de los ingenieros en s√≠ mismos.

Vea tambi√©n:

- [Ley de Gall](#ley-de-gall)

### YAGNI

[YAGNI en Wikipedia](https://es.wikipedia.org/wiki/YAGNI)

Este es un acr√≥nimo para (en ingl√©s) _**Y**ou **A**ren't **G**onna **N**eed **I**t_ o _No vas a necesitarlo_.

> Siempre implementar cosas cuando vayas a necesitarlas realmente, nunca cuando preveas que las necesitar√°s.
>
> ([Ron Jeffries](https://twitter.com/RonJeffries)) (XP co-fundador y autor del libro "Extreme Programming Installed")

Este principio de _Extreme Programming_ (XP) sugiere a los desarrolladores que deben solo implementar funcionalidad que es necesaria para los requisitos inmediatos y evitar los intentos de predecir el futuro implementando funcionalidades que podr√≠an necesitarse luego.

Adherirse a este principio debe reducir la cantidad de c√≥digo sin usar en la base de c√≥digo y evitar tiempo y esfuerzo de ser malgastado en funcionalidades que no aportan valor.

Vea tambi√©n:

- [Lista de lectura: Extreme Programming Installed](#lista-de-lectura)


## Lista de Lectura

Si has encontrado estos conceptos interesantes, puede que disfrutes estos libros:

- [Extreme Programming Installed - Ron Jeffries, Ann Anderson, Chet Hendrikson](https://www.goodreads.com/en/book/show/67834) - Covers the core principles of Extreme Programming.
- [El M√≠tico Hombre Mes](https://es.wikipedia.org/wiki/El_M%C3%ADtico_Hombre-Mes) - [The Mythical Man Month - Frederick P. Brooks Jr.](https://www.goodreads.com/book/show/13629.The_Mythical_Man_Month) - A classic volume on software engineering. [Brooks' Law](#brooks-law) is a central theme of the book.
- [G√∂del, Escher, Bach: An Eternal Golden Braid - Douglas R. Hofstadter.](https://www.goodreads.com/book/show/24113.G_del_Escher_Bach) - This book is difficult to classify. [Hofstadter's Law](#hofstadters-law) is from the book.
- [The Dilbert Principle - Adam Scott](https://www.goodreads.com/book/show/85574.The_Dilbert_Principle) - A comic look at corporate America, from the author who created the [Dilbert Principle](#the-dilbert-principl).
- [The Peter Principle - Lawrence J. Peter](https://www.goodreads.com/book/show/890728.The_Peter_Principle) - Another comic look at the challenges of larger organisations and people management, the source of [The Peter Principle](#the-peter-principle).

## Por Hacer

¬°Hola! Si llegaste aqu√≠ es porque hiciste clic en un enlace a un tema que a√∫n no ha sido escrito, perd√≥n por eso, ¬°este es a√∫n un trabajo en proceso!

S√© libre de [Abrir un _Issue_](https://github.com/manuel-rubio/hacker-laws/issues) para solicitar m√°s detalles, o [abre una petici√≥n de cambio (_pull request_)](https://github.com/manuel-rubio/hacker-laws/pulls) para enviar tus definiciones propuestas acerca del asunto.
